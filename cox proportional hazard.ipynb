{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DeepSurv from the repo\n",
    "import lasagne\n",
    "import deepsurv\n",
    "from deepsurv import deep_surv, utils\n",
    "\n",
    "from deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "from deepsurv import viz\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import resample \n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from bayes_opt import bayesian_optimization\n",
    "import optunity\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lifelines.CoxPHFitter: fitted with 1048 observations, 617 censored>\n",
      "      duration col = 'Time'\n",
      "         event col = 'Event'\n",
      "number of subjects = 1048\n",
      "  number of events = 431\n",
      "partial log-likelihood = -2577.852\n",
      "  time fit was run = 2019-10-07 06:35:53 UTC\n",
      "\n",
      "---\n",
      "    coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "1  0.036     1.037     0.005           0.027           0.046                1.027                1.047\n",
      "2  0.098     1.103     0.111          -0.120           0.315                0.887                1.371\n",
      "3 -0.062     0.940     0.011          -0.083          -0.042                0.920                0.959\n",
      "4  0.919     2.507     0.108           0.707           1.132                2.027                3.101\n",
      "5  0.249     1.283     0.104           0.046           0.452                1.047                1.571\n",
      "\n",
      "       z       p  -log2(p)\n",
      "1  7.633 <0.0005    45.313\n",
      "2  0.882   0.378     1.405\n",
      "3 -5.898 <0.0005    28.017\n",
      "4  8.475 <0.0005    55.242\n",
      "5  2.400   0.016     5.930\n",
      "---\n",
      "Concordance = 0.753\n",
      "Log-likelihood ratio test = 354.247 on 5 df, -log2(p)=244.731\n"
     ]
    }
   ],
   "source": [
    "# Cox Fitting\n",
    "cf = CoxPHFitter()\n",
    "cf.fit(train_df, 'Time', event_col='Event')\n",
    "\n",
    "cf.print_summary(decimals = 3)  # access the results using cf.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0 confidence interval 72.3% and 78.7%\n"
     ]
    }
   ],
   "source": [
    "#get CI to bootstrap\n",
    "# configure bootstrap\n",
    "n_iterations = 1000\n",
    "n_size = int(len(train_df) * 0.50)\n",
    "\n",
    "# run bootstrap\n",
    "stats = list()\n",
    "for i in range(n_iterations):\n",
    "    # prepare train and test sets\n",
    "    train = resample(train_df, n_samples=n_size)\n",
    "    # fit model\n",
    "    cf = CoxPHFitter()\n",
    "    cf.fit(train, 'Time', event_col='Event')\n",
    "    # evaluate model\n",
    "    score = cf.score_\n",
    "    stats.append(score)\n",
    "\n",
    "# confidence intervals\n",
    "alpha = 0.95\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(stats, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(stats, p))\n",
    "print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, bootstrap = False):\n",
    "    def ci(model):\n",
    "        def cph_ci(x, t, e, **kwargs):\n",
    "            return concordance_index(t,-model.predict_partial_hazard(x),e,)\n",
    "        return cph_ci\n",
    "\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Calculate c_index\n",
    "    metrics['c_index'] = ci(model)(**dataset)\n",
    "    if bootstrap:\n",
    "        metrics['c_index_bootstrap'] = utils.bootstrap_metric(ci(model), dataset)\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CPH Model\n",
      "<lifelines.CoxPHFitter: fitted with 1310 observations, 758 censored>\n",
      "      duration col = 'time'\n",
      "         event col = 'censor'\n",
      "number of subjects = 1310\n",
      "  number of events = 552\n",
      "partial log-likelihood = -3281.46\n",
      "  time fit was run = 2019-11-06 08:08:20 UTC\n",
      "\n",
      "---\n",
      "   coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "0  1.73      5.65      0.09            1.55            1.92                 4.69                 6.79\n",
      "1  0.03      1.03      0.00            0.03            0.04                 1.03                 1.04\n",
      "2  0.05      1.06      0.10           -0.14            0.24                 0.87                 1.27\n",
      "3 -0.05      0.95      0.01           -0.07           -0.03                 0.94                 0.97\n",
      "4  0.76      2.13      0.10            0.57            0.95                 1.76                 2.58\n",
      "5  0.27      1.32      0.09            0.09            0.45                 1.10                 1.57\n",
      "\n",
      "      z      p  -log2(p)\n",
      "0 18.35 <0.005    247.41\n",
      "1  8.16 <0.005     51.36\n",
      "2  0.56   0.58      0.79\n",
      "3 -5.07 <0.005     21.24\n",
      "4  7.82 <0.005     47.45\n",
      "5  2.99 <0.005      8.50\n",
      "---\n",
      "Concordance = 0.82\n",
      "Log-likelihood ratio test = 729.67 on 6 df, -log2(p)=510.32\n",
      "Train Likelihood: -3281.460828315265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\lifelines\\utils\\__init__.py:920: ConvergenceWarning: Column 0 have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
      "\n",
      ">>> events = df['censor'].astype(bool)\n",
      ">>> print(df.loc[events, '0'].var())\n",
      ">>> print(df.loc[~events, '0'].var())\n",
      "\n",
      "A very low variance means that the column 0 completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression \n",
      "  warnings.warn(warning_text, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'c_index': 0.8160032357005629, 'c_index_bootstrap': {'mean': 0.8180394000479096, 'confidence_interval': (0.8145077431219854, 0.8215710569738339)}}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import uuid\n",
    "import time\n",
    "localtime   = time.localtime()\n",
    "TIMESTRING  = time.strftime(\"%m%d%Y%M\", localtime)\n",
    "\n",
    "DURATION_COL = 'time'\n",
    "EVENT_COL = 'censor'\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/whas_train_test.h5')\n",
    "\n",
    "    # Train CPH model\n",
    "    print(\"Training CPH Model\")\n",
    "    train_df = utils.format_dataset_to_df(datasets['train'], DURATION_COL, EVENT_COL)\n",
    "    cf = CoxPHFitter()\n",
    "    results = cf.fit(train_df, duration_col=DURATION_COL, event_col=EVENT_COL)\n",
    "    cf.print_summary()\n",
    "    print(\"Train Likelihood: \" + str(cf._log_likelihood))\n",
    "\n",
    "    if 'valid' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['valid'])\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['test'], bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CPH Model\n",
      "<lifelines.CoxPHFitter: fitted with 7098 observations, 2275 censored>\n",
      "      duration col = 'Time'\n",
      "         event col = 'Event'\n",
      "number of subjects = 7098\n",
      "  number of events = 4823\n",
      "partial log-likelihood = -39956.9854\n",
      "  time fit was run = 2019-12-24 02:37:32 UTC\n",
      "\n",
      "---\n",
      "      coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "0   0.0142    1.0143    0.0010          0.0122          0.0162               1.0123               1.0163\n",
      "1  -0.0935    0.9107    0.0293         -0.1510         -0.0361               0.8598               0.9646\n",
      "2   0.0241    1.0244    0.0119          0.0007          0.0475               1.0007               1.0486\n",
      "3   0.0197    1.0199    0.0238         -0.0270          0.0664               0.9734               1.0687\n",
      "4  -0.0469    0.9541    0.0398         -0.1250          0.0311               0.8825               1.0316\n",
      "5   0.1321    1.1412    0.0784         -0.0217          0.2858               0.9786               1.3308\n",
      "6  -0.2592    0.7716    0.0280         -0.3142         -0.2043               0.7304               0.8153\n",
      "7  -0.0026    0.9974    0.0005         -0.0037         -0.0015               0.9964               0.9985\n",
      "8   0.0023    1.0023    0.0005          0.0013          0.0033               1.0013               1.0033\n",
      "9   0.0021    1.0022    0.0016         -0.0010          0.0053               0.9990               1.0053\n",
      "10  0.0115    1.0115    0.0125         -0.0131          0.0360               0.9870               1.0367\n",
      "11 -0.0038    0.9962    0.0025         -0.0087          0.0010               0.9914               1.0010\n",
      "12  0.0031    1.0031    0.0015          0.0002          0.0060               1.0002               1.0060\n",
      "13  0.0276    1.0279    0.0079          0.0120          0.0431               1.0121               1.0440\n",
      "\n",
      "         z      p  -log2(p)\n",
      "0  13.8953 <5e-05  143.4075\n",
      "1  -3.1911 0.0014    9.4626\n",
      "2   2.0180 0.0436    4.5199\n",
      "3   0.8271 0.4082    1.2927\n",
      "4  -1.1790 0.2384    2.0686\n",
      "5   1.6838 0.0922    3.4388\n",
      "6  -9.2425 <5e-05   65.1702\n",
      "7  -4.6889 <5e-05   18.4736\n",
      "8   4.6024 <5e-05   17.8690\n",
      "9   1.3483 0.1776    2.4935\n",
      "10  0.9148 0.3603    1.4728\n",
      "11 -1.5590 0.1190    3.0710\n",
      "12  2.1021 0.0355    4.8141\n",
      "13  3.4790 0.0005   10.9563\n",
      "---\n",
      "Concordance = 0.5694\n",
      "Log-likelihood ratio test = 353.5877 on 14 df, -log2(p)=219.7064\n",
      "Train Likelihood: -39956.98541187744\n",
      "Test metrics: {'c_index': 0.5830743459351149, 'c_index_bootstrap': {'mean': 0.5831051394843452, 'confidence_interval': (0.5814039088707377, 0.5848063700979527)}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/support_train_test.h5')\n",
    "\n",
    "    # Train CPH model\n",
    "    print(\"Training CPH Model\")\n",
    "    train_df = utils.format_dataset_to_df(datasets['train'], 'Time', 'Event')\n",
    "    cf = CoxPHFitter()\n",
    "    results = cf.fit(train_df, duration_col='Time', event_col='Event')\n",
    "    cf.print_summary(decimals = 4)\n",
    "    print(\"Train Likelihood: \" + str(cf._log_likelihood))\n",
    "\n",
    "    if 'valid' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['valid'])\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['test'], bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METABRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CPH Model\n",
      "<lifelines.CoxPHFitter: fitted with 1523 observations, 636 censored>\n",
      "      duration col = 'Time'\n",
      "         event col = 'Event'\n",
      "number of subjects = 1523\n",
      "  number of events = 887\n",
      "partial log-likelihood = -5752.2917\n",
      "  time fit was run = 2019-12-24 02:31:53 UTC\n",
      "\n",
      "---\n",
      "     coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "0  0.0422    1.0431    0.0471         -0.0501          0.1345               0.9511               1.1440\n",
      "1 -0.0698    0.9325    0.0381         -0.1446          0.0049               0.8654               1.0049\n",
      "2  0.1023    1.1077    0.0260          0.0514          0.1532               1.0527               1.1656\n",
      "3  0.3145    1.3696    0.1041          0.1104          0.5186               1.1167               1.6797\n",
      "4  0.1849    1.2031    0.0774          0.0333          0.3366               1.0338               1.4001\n",
      "5 -0.2118    0.8091    0.0709         -0.3508         -0.0729               0.7041               0.9297\n",
      "6  0.7713    2.1625    0.1132          0.5495          0.9931               1.7323               2.6995\n",
      "7  0.0693    1.0718    0.1159         -0.1578          0.2964               0.8540               1.3450\n",
      "8  0.0433    1.0443    0.0034          0.0367          0.0500               1.0374               1.0513\n",
      "\n",
      "        z      p  -log2(p)\n",
      "0  0.8957 0.3704    1.4329\n",
      "1 -1.8322 0.0669    3.9012\n",
      "2  3.9389 0.0001   13.5763\n",
      "3  3.0198 0.0025    8.6271\n",
      "4  2.3898 0.0169    5.8905\n",
      "5 -2.9877 0.0028    8.4746\n",
      "6  6.8152 <5e-05   36.6282\n",
      "7  0.5982 0.5497    0.8633\n",
      "8 12.7854 <5e-05  121.9263\n",
      "---\n",
      "Concordance = 0.6408\n",
      "Log-likelihood ratio test = 248.7654 on 9 df, -log2(p)=158.5902\n",
      "Train Likelihood: -5752.291709328949\n",
      "Test metrics: {'c_index': 0.6323629818136677, 'c_index_bootstrap': {'mean': 0.6316868444600475, 'confidence_interval': (0.6272362744945895, 0.6361374144255055)}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/metabric_IHC4_clinical_train_test.h5')\n",
    "\n",
    "    # Train CPH model\n",
    "    print(\"Training CPH Model\")\n",
    "    train_df = utils.format_dataset_to_df(datasets['train'], 'Time', 'Event')\n",
    "    cf = CoxPHFitter()\n",
    "    results = cf.fit(train_df, duration_col='Time', event_col='Event')\n",
    "    cf.print_summary(decimals = 4)\n",
    "    print(\"Train Likelihood: \" + str(cf._log_likelihood))\n",
    "\n",
    "    if 'valid' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['valid'])\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['test'], bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CPH Model\n",
      "<lifelines.CoxPHFitter: fitted with 1546 observations, 578 censored>\n",
      "      duration col = 'time'\n",
      "         event col = 'censor'\n",
      "number of subjects = 1546\n",
      "  number of events = 968\n",
      "partial log-likelihood = -6570.24803\n",
      "  time fit was run = 2019-11-06 08:12:10 UTC\n",
      "\n",
      "---\n",
      "      coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "0 -0.31716   0.72821   0.08392        -0.48163        -0.15269              0.61777              0.85840\n",
      "1  0.33792   1.40203   0.04969         0.24054         0.43530              1.27193              1.54543\n",
      "2  0.25593   1.29166   0.11225         0.03592         0.47594              1.03658              1.60952\n",
      "3  0.00256   1.00257   0.00419        -0.00566         0.01078              0.99436              1.01084\n",
      "4  0.05572   1.05730   0.00547         0.04500         0.06644              1.04603              1.06870\n",
      "5 -0.00026   0.99974   0.00014        -0.00053         0.00000              0.99947              1.00000\n",
      "6 -0.00028   0.99973   0.00013        -0.00054        -0.00001              0.99946              0.99999\n",
      "\n",
      "         z       p  -log2(p)\n",
      "0 -3.77948 0.00016  12.63553\n",
      "1  6.80121  <5e-06  36.48815\n",
      "2  2.28000 0.02261   5.46703\n",
      "3  0.61091 0.54126   0.88560\n",
      "4 10.18556  <5e-06  78.52439\n",
      "5 -1.94145 0.05220   4.25972\n",
      "6 -2.04385 0.04097   4.60936\n",
      "---\n",
      "Concordance = 0.66253\n",
      "Log-likelihood ratio test = 227.48117 on 7 df, -log2(p)=148.71983\n",
      "Train Likelihood: -6570.248032117349\n",
      "Test metrics: {'c_index': 0.6562913310087772, 'c_index_bootstrap': {'mean': 0.657971486634967, 'confidence_interval': (0.654712681512054, 0.66123029175788)}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/gbsg_cancer_train_test.h5')\n",
    "\n",
    "    # Train CPH model\n",
    "    print(\"Training CPH Model\")\n",
    "    train_df = utils.format_dataset_to_df(datasets['train'], DURATION_COL, EVENT_COL)\n",
    "    cf = CoxPHFitter()\n",
    "    results = cf.fit(train_df, duration_col=DURATION_COL, event_col=EVENT_COL)\n",
    "    cf.print_summary(decimals = 5)\n",
    "    print(\"Train Likelihood: \" + str(cf._log_likelihood))\n",
    "\n",
    "    if 'valid' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['valid'])\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        metrics = evaluate_model(cf, datasets['test'], bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_number :  4028\n",
      "feature_number :  8\n",
      "censored_number :  3457\n",
      "censored_rate :  85.82423038728898\n"
     ]
    }
   ],
   "source": [
    "#nwtco 데이터 불러오기\n",
    "nwtco = pd.read_csv('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/nwtco.csv')\n",
    "train_df = nwtco.drop('seqno', axis = 1)\n",
    "train_df = train_df.rename(columns = {'rel':'Event', 'edrel':'Time'})\n",
    "\n",
    "#censored number\n",
    "c_number = train_df['Event'].value_counts()[0]\n",
    "feat_num = len(list(train_df.columns))\n",
    "total_number = len(train_df['Event'])\n",
    "c_rate = (c_number / total_number) * 100\n",
    "\n",
    "print(\"total_number : \", total_number)\n",
    "print(\"feature_number : \", feat_num)\n",
    "print(\"censored_number : \", c_number)\n",
    "print(\"censored_rate : \" , c_rate)\n",
    "\n",
    "#data split\n",
    "train_df, test_df = train_test_split(train_df, test_size = 0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lifelines.CoxPHFitter: fitted with 2577 observations, 2216 censored>\n",
      "      duration col = 'Time'\n",
      "         event col = 'Event'\n",
      "number of subjects = 2577\n",
      "  number of events = 361\n",
      "partial log-likelihood = -2667.1964\n",
      "  time fit was run = 2019-12-24 02:39:05 UTC\n",
      "\n",
      "---\n",
      "                coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "instit        0.1526    1.1649    0.1824         -0.2049          0.5102               0.8147               1.6656\n",
      "histol        1.4946    4.4576    0.1703          1.1608          1.8284               3.1925               6.2239\n",
      "stage         0.3401    1.4050    0.0511          0.2399          0.4403               1.2711               1.5531\n",
      "study        -0.0424    0.9585    0.1065         -0.2512          0.1664               0.7779               1.1810\n",
      "age           0.0054    1.0054    0.0016          0.0023          0.0085               1.0023               1.0085\n",
      "in.subcohort -0.1521    0.8589    0.1489         -0.4440          0.1397               0.6415               1.1499\n",
      "\n",
      "                   z      p  -log2(p)\n",
      "instit        0.8367 0.4027    1.3121\n",
      "histol        8.7758 <5e-05   59.0311\n",
      "stage         6.6534 <5e-05   35.0228\n",
      "study        -0.3981 0.6906    0.5341\n",
      "age           3.4072 0.0007   10.5735\n",
      "in.subcohort -1.0219 0.3068    1.7045\n",
      "---\n",
      "Concordance = 0.7104\n",
      "Log-likelihood ratio test = 243.9832 on 6 df, -log2(p)=163.1117\n"
     ]
    }
   ],
   "source": [
    "# Cox Fitting\n",
    "cf = CoxPHFitter()\n",
    "cf.fit(train_df, 'Time', event_col='Event')\n",
    "\n",
    "cf.print_summary(decimals = 4)  # access the results using cf.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0 confidence interval 67.7% and 75.4%\n"
     ]
    }
   ],
   "source": [
    "#get CI to bootstrap\n",
    "# configure bootstrap\n",
    "n_iterations = 1000\n",
    "n_size = int(len(train_df) * 0.50)\n",
    "\n",
    "# run bootstrap\n",
    "stats = list()\n",
    "for i in range(n_iterations):\n",
    "    # prepare train and test sets\n",
    "    train = resample(train_df, n_samples=n_size)\n",
    "    # fit model\n",
    "    cf = CoxPHFitter()\n",
    "    cf.fit(train, 'Time', event_col='Event')\n",
    "    # evaluate model\n",
    "    score = cf.score_\n",
    "    stats.append(score)\n",
    "\n",
    "# confidence intervals\n",
    "alpha = 0.95\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(stats, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(stats, p))\n",
    "print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "def generate_data(treatment_group = False):\n",
    "    np.random.seed(123)\n",
    "    sd = deepsurv.datasets.SimulatedData(5, num_features = 9,\n",
    "        treatment_group = treatment_group)\n",
    "    train_data = sd.generate_data(1000,method = 'gaussian')\n",
    "    valid_data = sd.generate_data(400,method = 'gaussian')\n",
    "    test_data = sd.generate_data(400,method = 'gaussian')\n",
    "\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "train_data, valid_data, test_data = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CPH Model\n",
      "<lifelines.CoxPHFitter: fitted with 1000 observations, 80 censored>\n",
      "      duration col = 't'\n",
      "         event col = 'e'\n",
      "number of subjects = 1000\n",
      "  number of events = 920\n",
      "partial log-likelihood = -5629.63\n",
      "  time fit was run = 2019-11-06 05:04:26 UTC\n",
      "\n",
      "---\n",
      "   coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "0 -0.18      0.83      0.05           -0.28           -0.08                 0.75                 0.92\n",
      "1  0.04      1.04      0.05           -0.07            0.14                 0.93                 1.15\n",
      "2  0.11      1.12      0.06           -0.00            0.23                 1.00                 1.26\n",
      "3 -0.02      0.98      0.06           -0.14            0.09                 0.87                 1.09\n",
      "4  0.00      1.00      0.06           -0.11            0.11                 0.90                 1.12\n",
      "5 -0.01      0.99      0.06           -0.12            0.11                 0.89                 1.11\n",
      "6  0.07      1.07      0.06           -0.05            0.18                 0.96                 1.20\n",
      "7 -0.00      1.00      0.06           -0.12            0.11                 0.89                 1.12\n",
      "8 -0.01      0.99      0.06           -0.12            0.10                 0.89                 1.11\n",
      "\n",
      "      z      p  -log2(p)\n",
      "0 -3.44 <0.005     10.76\n",
      "1  0.69   0.49      1.03\n",
      "2  1.89   0.06      4.11\n",
      "3 -0.42   0.67      0.57\n",
      "4  0.03   0.98      0.03\n",
      "5 -0.12   0.91      0.14\n",
      "6  1.18   0.24      2.06\n",
      "7 -0.03   0.98      0.03\n",
      "8 -0.14   0.89      0.17\n",
      "---\n",
      "Concordance = 0.55\n",
      "Log-likelihood ratio test = 17.64 on 9 df, -log2(p)=4.66\n",
      "Train Likelihood: -5629.634818998373\n",
      "Valid metrics: {'c_index': 0.5021436497528498}\n",
      "Test metrics: {'c_index': 0.5205670550088602, 'c_index_bootstrap': {'mean': 0.518395814491158, 'confidence_interval': (0.5152208319486479, 0.5215707970336682)}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Train CPH model\n",
    "    print(\"Training CPH Model\")\n",
    "    train_df = utils.format_dataset_to_df(train_data, 't', 'e')\n",
    "    cf = CoxPHFitter()\n",
    "    results = cf.fit(train_df, duration_col='t', event_col='e')\n",
    "    cf.print_summary()\n",
    "    print(\"Train Likelihood: \" + str(cf._log_likelihood))\n",
    "\n",
    "    metrics = evaluate_model(cf, valid_data)\n",
    "    print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    metrics = evaluate_model(cf, test_data, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(treatment_group = False):\n",
    "    np.random.seed(123)\n",
    "    sd = deepsurv.datasets.SimulatedData(5, num_features = 9,\n",
    "        treatment_group = treatment_group)\n",
    "    train_data = sd.generate_data(1000,method = 'linear')\n",
    "    valid_data = sd.generate_data(400,method = 'linear')\n",
    "    test_data = sd.generate_data(400,method = 'linear')\n",
    "\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "train_data, valid_data, test_data = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CPH Model\n",
      "<lifelines.CoxPHFitter: fitted with 1000 observations, 172 censored>\n",
      "      duration col = 't'\n",
      "         event col = 'e'\n",
      "number of subjects = 1000\n",
      "  number of events = 828\n",
      "partial log-likelihood = -4811.95\n",
      "  time fit was run = 2019-11-06 05:04:39 UTC\n",
      "\n",
      "---\n",
      "   coef exp(coef)  se(coef)  coef lower 95%  coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
      "0  0.80      2.22      0.06            0.67            0.92                 1.96                 2.52\n",
      "1  2.03      7.61      0.08            1.87            2.19                 6.49                 8.91\n",
      "2  0.21      1.23      0.06            0.08            0.33                 1.08                 1.39\n",
      "3 -0.04      0.96      0.06           -0.16            0.08                 0.85                 1.09\n",
      "4  0.04      1.04      0.06           -0.08            0.16                 0.92                 1.17\n",
      "5 -0.03      0.97      0.06           -0.15            0.09                 0.86                 1.09\n",
      "6  0.01      1.01      0.06           -0.11            0.13                 0.89                 1.14\n",
      "7 -0.03      0.97      0.06           -0.15            0.09                 0.86                 1.09\n",
      "8 -0.07      0.93      0.06           -0.19            0.05                 0.83                 1.05\n",
      "\n",
      "      z      p  -log2(p)\n",
      "0 12.65 <0.005    119.38\n",
      "1 25.09 <0.005    459.19\n",
      "2  3.25 <0.005      9.77\n",
      "3 -0.64   0.52      0.94\n",
      "4  0.60   0.55      0.87\n",
      "5 -0.47   0.64      0.65\n",
      "6  0.16   0.87      0.20\n",
      "7 -0.52   0.61      0.72\n",
      "8 -1.13   0.26      1.94\n",
      "---\n",
      "Concordance = 0.77\n",
      "Log-likelihood ratio test = 766.63 on 9 df, -log2(p)=526.50\n",
      "Train Likelihood: -4811.948974618726\n",
      "Valid metrics: {'c_index': 0.7776857439619242}\n",
      "Test metrics: {'c_index': 0.7856530214424952, 'c_index_bootstrap': {'mean': 0.7825060281581965, 'confidence_interval': (0.7805032627277788, 0.7845087935886141)}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Train CPH model\n",
    "    print(\"Training CPH Model\")\n",
    "    train_df = utils.format_dataset_to_df(train_data, 't', 'e')\n",
    "    cf = CoxPHFitter()\n",
    "    results = cf.fit(train_df, duration_col='t', event_col='e')\n",
    "    cf.print_summary()\n",
    "    print(\"Train Likelihood: \" + str(cf._log_likelihood))\n",
    "\n",
    "    metrics = evaluate_model(cf, valid_data)\n",
    "    print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    metrics = evaluate_model(cf, test_data, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
