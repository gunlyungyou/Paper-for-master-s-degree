{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "import lasagne\n",
    "import numpy\n",
    "import time\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Use DeepSurv from the repo\n",
    "import lasagne\n",
    "from deepsurv import deep_surv, utils\n",
    "\n",
    "from deepsurv.deepsurv_logger import DeepSurvLogger, TensorboardLogger\n",
    "from deepsurv import viz\n",
    "\n",
    "\n",
    "import deepsurv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from bayes_opt import bayesian_optimization\n",
    "import optunity\n",
    "\n",
    "from lasagne.regularization import regularize_layer_params, l1, l2\n",
    "from lasagne.nonlinearities import rectify,selu\n",
    "\n",
    "class DeepSurv:\n",
    "    def __init__(self, n_in,\n",
    "    learning_rate, hidden_layers_sizes = None,\n",
    "    lr_decay = 0.0, momentum = 0.9,\n",
    "    L2_reg = 0.0, L1_reg = 0.0,\n",
    "    activation = \"selu\",\n",
    "    dropout = None,\n",
    "    batch_norm = False,\n",
    "    standardize = False,\n",
    "    ):\n",
    "\n",
    "        self.X = T.matrix('x')  # patients covariates\n",
    "        self.E = T.ivector('e') # the observations vector\n",
    "\n",
    "        # Default Standardization Values: mean = 0, std = 1\n",
    "        self.offset = numpy.zeros(shape = n_in, dtype=numpy.float32)\n",
    "        self.scale = numpy.ones(shape = n_in, dtype=numpy.float32)\n",
    "\n",
    "        # self.offset = theano.shared(numpy.zeros(shape = n_in, dtype=numpy.float32))\n",
    "        # self.scale = theano.shared(numpy.ones(shape = n_in, dtype=numpy.float32))\n",
    "\n",
    "        network = lasagne.layers.InputLayer(shape=(None,n_in),\n",
    "            input_var = self.X)\n",
    "        \n",
    "        network = lasagne.layers.ReshapeLayer(network, (-1,1,n_in))\n",
    "\n",
    "        # if standardize:\n",
    "        #     network = lasagne.layers.standardize(network,self.offset,\n",
    "        #                                         self.scale,\n",
    "        #                                         shared_axes = 0)\n",
    "        self.standardize = standardize\n",
    "\n",
    "        if activation == 'rectify':\n",
    "            activation_fn = rectify\n",
    "        elif activation == 'selu':\n",
    "            activation_fn = selu\n",
    "        else:\n",
    "            raise IllegalArgumentException(\"Unknown activation function: %s\" % activation)\n",
    "\n",
    "        # Construct Neural Network\n",
    "        for n_layer in (hidden_layers_sizes or []):\n",
    "            if activation_fn == lasagne.nonlinearities.rectify:\n",
    "                W_init = lasagne.init.GlorotUniform()\n",
    "            else:\n",
    "                # TODO: implement other initializations\n",
    "                W_init = lasagne.init.GlorotUniform()\n",
    "\n",
    "            network = lasagne.layers.LSTMLayer(\n",
    "                network, num_units = n_layer,\n",
    "                nonlinearity = activation_fn\n",
    "            )\n",
    "\n",
    "            if batch_norm:\n",
    "                network = lasagne.layers.batch_norm(network)\n",
    "\n",
    "            if not dropout is None:\n",
    "                network = lasagne.layers.DropoutLayer(network, p = dropout)\n",
    "\n",
    "        # Combine Linear to output Log Hazard Ratio - same as Faraggi\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "            network, num_units = 1,\n",
    "            nonlinearity = lasagne.nonlinearities.linear,\n",
    "            W = lasagne.init.GlorotUniform()\n",
    "        )\n",
    "\n",
    "        self.network = network\n",
    "        self.params = lasagne.layers.get_all_params(self.network,\n",
    "                                                    trainable = True)\n",
    "        self.hidden_layers = lasagne.layers.get_all_layers(self.network)[1:]\n",
    "\n",
    "        # Relevant Functions\n",
    "        self.partial_hazard = T.exp(self.risk(deterministic = True)) # e^h(x)\n",
    "\n",
    "        # Store and set needed Hyper-parameters:\n",
    "        self.hyperparams = {\n",
    "            'n_in': n_in,\n",
    "            'learning_rate': learning_rate,\n",
    "            'hidden_layers_sizes': hidden_layers_sizes,\n",
    "            'lr_decay': lr_decay,\n",
    "            'momentum': momentum,\n",
    "            'L2_reg': L2_reg,\n",
    "            'L1_reg': L1_reg,\n",
    "            'activation': activation,\n",
    "            'dropout': dropout,\n",
    "            'batch_norm': batch_norm,\n",
    "            'standardize': standardize\n",
    "        }\n",
    "\n",
    "        self.n_in = n_in\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_decay = lr_decay\n",
    "        self.L2_reg = L2_reg\n",
    "        self.L1_reg = L1_reg\n",
    "        self.momentum = momentum\n",
    "        self.restored_update_params = None\n",
    "\n",
    "    def _negative_log_likelihood(self, E, deterministic = False):\n",
    "        risk = self.risk(deterministic)\n",
    "        hazard_ratio = T.exp(risk)\n",
    "        log_risk = T.log(T.extra_ops.cumsum(hazard_ratio))\n",
    "        uncensored_likelihood = risk.T - log_risk\n",
    "        censored_likelihood = uncensored_likelihood * E\n",
    "        num_observed_events = T.sum(E)\n",
    "        neg_likelihood = -T.sum(censored_likelihood) / num_observed_events\n",
    "        return neg_likelihood\n",
    "\n",
    "    def _get_loss_updates(self,\n",
    "    L1_reg = 0.0, L2_reg = 0.001,\n",
    "    update_fn = lasagne.updates.nesterov_momentum,\n",
    "    max_norm = None, deterministic = False,\n",
    "    momentum = 0.9,\n",
    "    **kwargs):\n",
    "\n",
    "        loss = (\n",
    "            self._negative_log_likelihood(self.E, deterministic)\n",
    "            + regularize_layer_params(self.network,l1) * L1_reg\n",
    "            + regularize_layer_params(self.network, l2) * L2_reg\n",
    "        )\n",
    "\n",
    "        if max_norm:\n",
    "            grads = T.grad(loss,self.params)\n",
    "            scaled_grads = lasagne.updates.total_norm_constraint(grads, max_norm)\n",
    "            updates = update_fn(\n",
    "                scaled_grads, self.params, **kwargs\n",
    "            )\n",
    "        else:\n",
    "            updates = update_fn(\n",
    "                loss, self.params, **kwargs\n",
    "            )\n",
    "\n",
    "        if momentum:\n",
    "            updates = lasagne.updates.apply_nesterov_momentum(updates, \n",
    "                self.params, self.learning_rate, momentum=momentum)\n",
    "\n",
    "        # If the model was loaded from file, reload params\n",
    "        if self.restored_update_params:\n",
    "            for p, value in zip(updates.keys(), self.restored_update_params):\n",
    "                p.set_value(value)\n",
    "            self.restored_update_params = None\n",
    "\n",
    "        # Store last update function to be later saved\n",
    "        self.updates = updates\n",
    "\n",
    "        return loss, updates\n",
    "\n",
    "    def _get_train_valid_fn(self,\n",
    "    L1_reg, L2_reg, learning_rate,\n",
    "    **kwargs):\n",
    "\n",
    "        loss, updates = self._get_loss_updates(\n",
    "            L1_reg, L2_reg, deterministic = False,\n",
    "            learning_rate=learning_rate, **kwargs\n",
    "        )\n",
    "        train_fn = theano.function(\n",
    "            inputs = [self.X, self.E],\n",
    "            outputs = loss,\n",
    "            updates = updates,\n",
    "            name = 'train'\n",
    "        )\n",
    "\n",
    "        valid_loss, _ = self._get_loss_updates(\n",
    "            L1_reg, L2_reg, deterministic = True,\n",
    "            learning_rate=learning_rate, **kwargs\n",
    "        )\n",
    "\n",
    "        valid_fn = theano.function(\n",
    "            inputs = [self.X, self.E],\n",
    "            outputs = valid_loss,\n",
    "            name = 'valid'\n",
    "        )\n",
    "        return train_fn, valid_fn\n",
    "\n",
    "    def get_concordance_index(self, x, t, e, **kwargs):\n",
    "\n",
    "        compute_hazards = theano.function(\n",
    "            inputs = [self.X],\n",
    "            outputs = -self.partial_hazard\n",
    "        )\n",
    "        partial_hazards = compute_hazards(x)\n",
    "\n",
    "        return concordance_index(t,\n",
    "            partial_hazards,\n",
    "            e)\n",
    "\n",
    "    def _standardize_x(self, x):\n",
    "        return (x - self.offset) / self.scale\n",
    "\n",
    "    # @TODO: implement for varios instances of datasets\n",
    "    def prepare_data(self,dataset):\n",
    "        if isinstance(dataset, dict):\n",
    "            x, e, t = dataset['x'], dataset['e'], dataset['t']\n",
    "\n",
    "        if self.standardize:\n",
    "            x = self._standardize_x(x)\n",
    "\n",
    "        # Sort Training Data for Accurate Likelihood\n",
    "        sort_idx = numpy.argsort(t)[::-1]\n",
    "        x = x[sort_idx]\n",
    "        e = e[sort_idx]\n",
    "        t = t[sort_idx]\n",
    "\n",
    "        return (x, e, t)\n",
    "\n",
    "    def train(self,\n",
    "    train_data, valid_data= None,\n",
    "    n_epochs = 500,\n",
    "    validation_frequency = 250,\n",
    "    patience = 2000, improvement_threshold = 0.99999, patience_increase = 2,\n",
    "    logger = None,\n",
    "    update_fn = lasagne.updates.nesterov_momentum,\n",
    "    verbose = True,\n",
    "    **kwargs):\n",
    "\n",
    "        if logger is None:\n",
    "            logger = DeepSurvLogger('DeepSurv')\n",
    "\n",
    "        # Set Standardization layer offset and scale to training data mean and std\n",
    "        if self.standardize:\n",
    "            self.offset = train_data['x'].mean(axis = 0)\n",
    "            self.scale = train_data['x'].std(axis = 0)\n",
    "\n",
    "        x_train, e_train, t_train = self.prepare_data(train_data)\n",
    "\n",
    "        if valid_data:\n",
    "            x_valid, e_valid, t_valid = self.prepare_data(valid_data)\n",
    "\n",
    "        # Initialize Metrics\n",
    "        best_validation_loss = numpy.inf\n",
    "        best_params = None\n",
    "        best_params_idx = -1\n",
    "\n",
    "        # Initialize Training Parameters\n",
    "        lr = theano.shared(numpy.array(self.learning_rate,\n",
    "                                    dtype = numpy.float32))\n",
    "        momentum = numpy.array(0, dtype= numpy.float32)\n",
    "\n",
    "        train_fn, valid_fn = self._get_train_valid_fn(\n",
    "            L1_reg=self.L1_reg, L2_reg=self.L2_reg,\n",
    "            learning_rate=lr,\n",
    "            momentum = momentum,\n",
    "            update_fn = update_fn, **kwargs\n",
    "        )\n",
    "\n",
    "        start = time.time()\n",
    "        for epoch in range(n_epochs):\n",
    "            # Power-Learning Rate Decay\n",
    "            lr = self.learning_rate / (1 + epoch * self.lr_decay)\n",
    "            logger.logValue('lr', lr, epoch)\n",
    "\n",
    "            if self.momentum and epoch >= 10:\n",
    "                momentum = self.momentum\n",
    "\n",
    "            loss = train_fn(x_train, e_train)\n",
    "\n",
    "            logger.logValue('loss', loss, epoch)\n",
    "            # train_loss.append(loss)\n",
    "\n",
    "            ci_train = self.get_concordance_index(\n",
    "                x_train,\n",
    "                t_train,\n",
    "                e_train,\n",
    "            )\n",
    "            logger.logValue('c-index',ci_train, epoch)\n",
    "            # train_ci.append(ci_train)\n",
    "\n",
    "            if valid_data and (epoch % validation_frequency == 0):\n",
    "                validation_loss = valid_fn(x_valid, e_valid)\n",
    "                logger.logValue('valid_loss',validation_loss, epoch)\n",
    "\n",
    "                ci_valid = self.get_concordance_index(\n",
    "                    x_valid,\n",
    "                    t_valid,\n",
    "                    e_valid\n",
    "                )\n",
    "                logger.logValue('valid_c-index', ci_valid, epoch)\n",
    "\n",
    "                if validation_loss < best_validation_loss:\n",
    "                    # improve patience if loss improves enough\n",
    "                    if validation_loss < best_validation_loss * improvement_threshold:\n",
    "                        patience = max(patience, epoch * patience_increase)\n",
    "\n",
    "                    best_params = [param.copy().eval() for param in self.params]\n",
    "                    best_params_idx = epoch\n",
    "                    best_validation_loss = validation_loss\n",
    "\n",
    "            if verbose and (epoch % validation_frequency == 0):\n",
    "                logger.print_progress_bar(epoch, n_epochs, loss, ci_train)\n",
    "\n",
    "            if patience <= epoch:\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            logger.logMessage('Finished Training with %d iterations in %0.2fs' % (\n",
    "                epoch + 1, time.time() - start\n",
    "            ))\n",
    "        logger.shutdown()\n",
    "        logger.history['best_valid_loss'] = best_validation_loss\n",
    "        logger.history['best_params'] = best_params\n",
    "        logger.history['best_params_idx'] = best_params_idx\n",
    "\n",
    "        return logger.history\n",
    "\n",
    "\n",
    "    def risk(self,deterministic = False):\n",
    "        \n",
    "        return lasagne.layers.get_output(self.network,\n",
    "                                        deterministic = deterministic)\n",
    "\n",
    "    def predict_risk(self, x):\n",
    "        risk_fxn = theano.function(\n",
    "            inputs = [self.X],\n",
    "            outputs = self.risk(deterministic= True),\n",
    "            name = 'predicted risk'\n",
    "        )\n",
    "        return risk_fxn(x)\n",
    "    \n",
    "    def recommend_treatment(self, x, trt_i, trt_j, trt_idx = -1):\n",
    "        \"\"\"\n",
    "        Computes recommendation function rec_ij(x) for two treatments i and j.\n",
    "            rec_ij(x) is the log of the hazards ratio of x in treatment i vs.\n",
    "            treatment j.\n",
    "        .. math::\n",
    "            rec_{ij}(x) = log(e^h_i(x) / e^h_j(x)) = h_i(x) - h_j(x)\n",
    "        Parameters:\n",
    "            x: (n, d) numpy array of observations\n",
    "            trt_i: treatment i value\n",
    "            trt_j: treatment j value\n",
    "            trt_idx: the index of x representing the treatment group column\n",
    "        Returns:\n",
    "            rec_ij: recommendation\n",
    "        \"\"\"\n",
    "        # Copy x to prevent overwritting data\n",
    "        x_trt = numpy.copy(x)\n",
    "\n",
    "        # Calculate risk of observations treatment i\n",
    "        x_trt[:,trt_idx] = trt_i\n",
    "        h_i = self.predict_risk(x_trt)\n",
    "        # Risk of observations in treatment j\n",
    "        x_trt[:,trt_idx] = trt_j;\n",
    "        h_j = self.predict_risk(x_trt)\n",
    "\n",
    "        rec_ij = h_i - h_j\n",
    "        return rec_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # \"0, 1\" for multiple GPUs\n",
    "# impoart tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# Allow growing memmory\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "import uuid\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import pylab\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "localtime   = time.localtime()\n",
    "TIMESTRING  = time.strftime(\"%m%d%Y%M\", localtime)\n",
    "\n",
    "def evaluate_model(model, dataset, bootstrap = False):\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Calculate c_index\n",
    "    metrics['c_index'] = model.get_concordance_index(**dataset)\n",
    "    if bootstrap:\n",
    "        metrics['c_index_bootstrap'] = utils.bootstrap_metric(model.get_concordance_index, dataset)\n",
    "    \n",
    "\n",
    "    return metrics\n",
    "\n",
    "def plot_survival_curves(rec_t, rec_e, antirec_t, antirec_e, experiment_name = '', output_file = None):\n",
    "    # Set-up plots\n",
    "    plt.figure(figsize=(12,3))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    # Fit survival curves\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(rec_t, event_observed=rec_e, label=' '.join([experiment_name, \"Recommendation\"]))  \n",
    "    print(\"rec median : \",kmf.median_)\n",
    "    kmf.plot(ax=ax,linestyle=\"-\")\n",
    "    kmf.fit(antirec_t, event_observed=antirec_e, label=' '.join([experiment_name, \"Non-recommendation\"]))\n",
    "    print(\"Non-rec median : \",kmf.median_)\n",
    "    kmf.plot(ax=ax,linestyle=\"--\")\n",
    "    \n",
    "    # Format graph\n",
    "    plt.ylim(0,1);\n",
    "    ax.set_xlabel('Timeline (months)',fontsize='large')\n",
    "    ax.set_ylabel('Percentage of Population Alive',fontsize='large')\n",
    "    \n",
    "    # Calculate p-value\n",
    "    results = logrank_test(rec_t, antirec_t, rec_e, antirec_e, alpha=.95)\n",
    "    results.print_summary()\n",
    "\n",
    "    # Location the label at the 1st out of 9 tick marks\n",
    "    xloc = max(np.max(rec_t),np.max(antirec_t)) / 9\n",
    "    plt.legend(loc='best',prop={'size':15})\n",
    "    print('p-value : ',results.p_value)\n",
    "\n",
    "\n",
    "    if output_file:\n",
    "        plt.tight_layout()\n",
    "        pylab.savefig(output_file)\n",
    "        \n",
    "        \n",
    "\n",
    "def save_treatment_rec_visualizations(model, dataset, output_dir, \n",
    "    trt_i = 1, trt_j = 0, trt_idx = 0):\n",
    "    \n",
    "    trt_values = np.unique(dataset['x'][:,trt_idx]) # 0,1\n",
    "    print(\"Recommending treatments:\", trt_values)\n",
    "    rec_trt = model.recommend_treatment(dataset['x'], trt_i, trt_j, trt_idx)\n",
    "    rec_trt = np.squeeze((rec_trt < 0).astype(np.int32))\n",
    "\n",
    "    rec_dict = utils.calculate_recs_and_antirecs(rec_trt, true_trt = trt_idx, dataset = dataset)\n",
    "    rec_dict_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in rec_dict.items() ]))\n",
    "    rec_dict_df.to_csv('C:/Users/ASUS/Dropbox/석사학위논문/rec_dict.csv', sep = ',')\n",
    "    \n",
    "    output_file = output_dir + 'trt_plot.pdf'\n",
    "    print(output_file)\n",
    "    plot_survival_curves(experiment_name = '', output_file=output_file, **rec_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## whas hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tunning\n",
    "datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/whas_train_test.h5')\n",
    "train_data = datasets['train']\n",
    "\n",
    "def get_optimizer_from_str(update_fn):\n",
    "    if update_fn == 'sgd':\n",
    "        return lasagne.updates.sgd\n",
    "    elif update_fn == 'adam':\n",
    "        return lasagne.updates.adam\n",
    "    elif update_fn == 'rmsprop':\n",
    "        return lasagne.updates.rmsprop\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_objective_function(num_epochs):\n",
    "\n",
    "    def format_to_deepsurv(x, y):\n",
    "        return {\n",
    "            'x': x,\n",
    "            'e': y[:,0].astype(np.int32),\n",
    "            't': y[:,1].astype(np.float32)\n",
    "        }\n",
    "\n",
    "    def get_hyperparams(params):\n",
    "        hyperparams = {\n",
    "            'batch_norm': False,\n",
    "            'activation': 'selu',\n",
    "            'standardize': True\n",
    "        }\n",
    "        # @TODO add default parameters and only take necessary args from params\n",
    "        # protect from params including some other key\n",
    "\n",
    "        if 'num_layers' in params and 'num_nodes' in params:\n",
    "            params['hidden_layers_sizes'] = [int(params['num_nodes'])] * int(params['num_layers'])\n",
    "            del params['num_layers']\n",
    "            del params['num_nodes']\n",
    "\n",
    "\n",
    "        hyperparams.update(params)\n",
    "        return hyperparams\n",
    "\n",
    "    def train_deepsurv(x_train, y_train, x_test, y_test,\n",
    "        **kwargs):\n",
    "        # Standardize the datasets\n",
    "        train_mean = x_train.mean(axis = 0)\n",
    "        train_std = x_train.std(axis = 0)\n",
    "\n",
    "        x_train = (x_train - train_mean) / train_std\n",
    "        x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "        train_data = format_to_deepsurv(x_train, y_train)\n",
    "        valid_data = format_to_deepsurv(x_test, y_test)\n",
    "\n",
    "        hyperparams = get_hyperparams(kwargs)\n",
    "\n",
    "        network = DeepSurv(n_in=x_train.shape[1], **hyperparams)\n",
    "        metrics = network.train(train_data, n_epochs = num_epochs,\n",
    "            update_fn = lasagne.updates.nesterov_momentum, verbose = False)\n",
    "\n",
    "        result = network.get_concordance_index(**valid_data)\n",
    "        return result\n",
    "\n",
    "    return train_deepsurv\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    NUM_EPOCHS = 500\n",
    "    NUM_FOLDS = 3\n",
    "\n",
    "    x = train_data['x']\n",
    "    e = train_data['e']\n",
    "    \n",
    "    t = train_data['t']\n",
    "    y = np.column_stack((e, t))\n",
    "    \n",
    "    \n",
    "\n",
    "    opt_fxn = get_objective_function(NUM_EPOCHS)\n",
    "    opt_fxn = optunity.cross_validated(x=x, y=y, num_folds=NUM_FOLDS,\n",
    "        strata=False)(opt_fxn)\n",
    "\n",
    "    opt_params, _, _ = optunity.maximize(opt_fxn, num_evals=20,\n",
    "        learning_rate =[0.01,0.1], \n",
    "        lr_decay = [0.0001, 0.001], \n",
    "        momentum = [0.8, 0.95],\n",
    "        L2_reg = [2.0, 7.0], \n",
    "        dropout = [0.1, 0.7],\n",
    "        num_layers = [1,3],\n",
    "        num_nodes = [20,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 3.2627952225224077,\n",
       " 'dropout': 0.18384765625,\n",
       " 'learning_rate': 0.0007684349218750001,\n",
       " 'lr_decay': 0.0008126617030571227,\n",
       " 'momentum': 0.89404296875,\n",
       " 'num_layers': 1.7864062500000002,\n",
       " 'num_nodes': 23.744140625}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#첫번쨰\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 3.31475192669958,\n",
       " 'dropout': 0.46938144168081264,\n",
       " 'learning_rate': 0.09832319779821613,\n",
       " 'lr_decay': 0.0006101093590170168,\n",
       " 'momentum': 0.8338525390625,\n",
       " 'num_layers': 1.4641958220661755,\n",
       " 'num_nodes': 26.564967441983242}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#두번째\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.8523798744639756}\n",
      "Test metrics: {'c_index': 0.8403384003505342, 'c_index_bootstrap': {'mean': 0.8436002241992917, 'confidence_interval': (0.8402740348386629, 0.8469264135599205)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "\"learning_rate\": 0.09832319779821613, \n",
    " \"dropout\": 0.46938144168081264, \n",
    " \"lr_decay\": 0.0006101093590170168, \n",
    " \"momentum\": 0.8338525390625, \n",
    " \"L2_reg\": 3.31475192669958, \n",
    " \"batch_norm\": False, \n",
    " \"standardize\": True, \n",
    " \"n_in\": 6, \n",
    " \"hidden_layers_sizes\": [26],\n",
    " \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/whas_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 700,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.8534143725420092}\n",
      "Test metrics: {'c_index': 0.8406080420641073, 'c_index_bootstrap': {'mean': 0.8391891618772475, 'confidence_interval': (0.8360070765817879, 0.8423712471727071)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "\"learning_rate\": 0.09832319779821613, \n",
    " \"dropout\": 0.46938144168081264, \n",
    " \"lr_decay\": 0.0006101093590170168, \n",
    " \"momentum\": 0.8338525390625, \n",
    " \"L2_reg\": 3.31475192669958, \n",
    " \"batch_norm\": False, \n",
    " \"standardize\": True, \n",
    " \"n_in\": 6, \n",
    " \"hidden_layers_sizes\": [26],\n",
    " \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/whas_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 700,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trt = numpy.copy(datasets['test']['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,4] = 1 #좌심 머시기가 있음\n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,4] = 0 #좌심 머시기가 없음\n",
    "h_0 = model.predict_risk(x_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.221963  ]\n",
      " [ 0.26267159]\n",
      " [ 0.25539342]\n",
      " [ 0.26304236]\n",
      " [ 0.21747058]\n",
      " [ 0.26446534]\n",
      " [ 0.25394489]\n",
      " [ 0.21868223]\n",
      " [ 0.21299887]\n",
      " [ 0.24370851]\n",
      " [ 0.23684588]\n",
      " [ 0.18150199]\n",
      " [ 0.2545483 ]\n",
      " [ 0.19429984]\n",
      " [ 0.26436187]\n",
      " [ 0.20953365]\n",
      " [ 0.26545092]\n",
      " [ 0.26499525]\n",
      " [ 0.28418968]\n",
      " [ 0.2244536 ]\n",
      " [ 0.20010662]\n",
      " [ 0.17934031]\n",
      " [ 0.22074594]\n",
      " [ 0.03947932]\n",
      " [ 0.2405055 ]\n",
      " [ 0.21927011]\n",
      " [ 0.1841517 ]\n",
      " [ 0.26446069]\n",
      " [ 0.1509082 ]\n",
      " [ 0.25801791]\n",
      " [ 0.18329206]\n",
      " [ 0.26208781]\n",
      " [ 0.1841517 ]\n",
      " [ 0.17586066]\n",
      " [ 0.26499525]\n",
      " [ 0.26556166]\n",
      " [ 0.05393019]\n",
      " [ 0.26532278]\n",
      " [ 0.23418948]\n",
      " [ 0.1841517 ]\n",
      " [ 0.23779762]\n",
      " [ 0.25859269]\n",
      " [ 0.24814371]\n",
      " [ 0.23331194]\n",
      " [ 0.26551173]\n",
      " [ 0.23587125]\n",
      " [ 0.231578  ]\n",
      " [ 0.20741532]\n",
      " [ 0.26383483]\n",
      " [ 0.22887484]\n",
      " [ 0.10623037]\n",
      " [-0.01041734]\n",
      " [ 0.24125174]\n",
      " [ 0.17831949]\n",
      " [ 0.26186707]\n",
      " [ 0.23633364]\n",
      " [ 0.24038689]\n",
      " [ 0.23273078]\n",
      " [ 0.21411468]\n",
      " [ 0.2307589 ]\n",
      " [ 0.22459326]\n",
      " [ 0.22687438]\n",
      " [ 0.26186707]\n",
      " [ 0.20172334]\n",
      " [ 0.24902121]\n",
      " [ 0.2621535 ]\n",
      " [ 0.25767135]\n",
      " [ 0.2779129 ]\n",
      " [ 0.26555591]\n",
      " [ 0.28889927]\n",
      " [ 0.26010936]\n",
      " [ 0.22826752]\n",
      " [ 0.20789141]\n",
      " [ 0.22347218]\n",
      " [ 0.22672861]\n",
      " [ 0.20214897]\n",
      " [ 0.242296  ]\n",
      " [ 0.10383847]\n",
      " [ 0.23313147]\n",
      " [ 0.2597048 ]\n",
      " [ 0.1794956 ]\n",
      " [ 0.13008639]\n",
      " [ 0.15648045]\n",
      " [ 0.16734852]\n",
      " [ 0.25394489]\n",
      " [ 0.21216804]\n",
      " [ 0.15726651]\n",
      " [ 0.18568378]\n",
      " [ 0.26560237]\n",
      " [ 0.221699  ]\n",
      " [ 0.25536571]\n",
      " [ 0.18133688]\n",
      " [ 0.26532278]\n",
      " [ 0.2455162 ]\n",
      " [ 0.20545838]\n",
      " [ 0.22466276]\n",
      " [ 0.25650287]\n",
      " [ 0.24017513]\n",
      " [ 0.26336063]\n",
      " [ 0.21747058]\n",
      " [ 0.11292633]\n",
      " [ 0.17868018]\n",
      " [ 0.221963  ]\n",
      " [ 0.2622092 ]\n",
      " [ 0.23909589]\n",
      " [ 0.19969377]\n",
      " [ 0.2523644 ]\n",
      " [ 0.20732053]\n",
      " [ 0.2779129 ]\n",
      " [ 0.23314157]\n",
      " [ 0.2284747 ]\n",
      " [ 0.2413787 ]\n",
      " [ 0.2176973 ]\n",
      " [ 0.21100811]\n",
      " [ 0.23862031]\n",
      " [ 0.24153835]\n",
      " [ 0.22650346]\n",
      " [ 0.20513118]\n",
      " [ 0.2310241 ]\n",
      " [ 0.25714564]\n",
      " [ 0.22188462]\n",
      " [ 0.15804336]\n",
      " [ 0.26560237]\n",
      " [ 0.18133688]\n",
      " [ 0.23888232]\n",
      " [ 0.21225403]\n",
      " [ 0.03487833]\n",
      " [ 0.21112115]\n",
      " [ 0.22457327]\n",
      " [ 0.24869698]\n",
      " [ 0.26419608]\n",
      " [ 0.1823994 ]\n",
      " [ 0.11386238]\n",
      " [ 0.20837869]\n",
      " [ 0.25603428]\n",
      " [ 0.2413787 ]\n",
      " [ 0.28335111]\n",
      " [ 0.19027469]\n",
      " [ 0.22492249]\n",
      " [ 0.23677772]\n",
      " [ 0.23304012]\n",
      " [-0.01041734]\n",
      " [ 0.12476236]\n",
      " [ 0.23332218]\n",
      " [ 0.23465328]\n",
      " [ 0.20545838]\n",
      " [ 0.20528488]\n",
      " [ 0.19022077]\n",
      " [ 0.23313181]\n",
      " [ 0.27075127]\n",
      " [ 0.23384411]\n",
      " [ 0.2651921 ]\n",
      " [ 0.22462497]\n",
      " [ 0.24254268]\n",
      " [ 0.22457327]\n",
      " [ 0.26304236]\n",
      " [ 0.26000084]\n",
      " [ 0.28016254]\n",
      " [ 0.18368439]\n",
      " [ 0.22031944]\n",
      " [ 0.19022077]\n",
      " [ 0.23598864]\n",
      " [ 0.13428584]\n",
      " [ 0.26246501]\n",
      " [ 0.26408565]\n",
      " [ 0.23366242]\n",
      " [ 0.10049878]\n",
      " [ 0.26341979]\n",
      " [-0.00845629]\n",
      " [ 0.1841517 ]\n",
      " [ 0.23331084]\n",
      " [ 0.23644918]\n",
      " [ 0.12517673]\n",
      " [ 0.21920925]\n",
      " [ 0.17285079]\n",
      " [ 0.20089698]\n",
      " [-0.00650833]\n",
      " [ 0.2327207 ]\n",
      " [ 0.22800871]\n",
      " [ 0.1794956 ]\n",
      " [ 0.18169197]\n",
      " [ 0.24370851]\n",
      " [ 0.24733628]\n",
      " [ 0.22394797]\n",
      " [ 0.25504724]\n",
      " [ 0.26119866]\n",
      " [ 0.23730984]\n",
      " [ 0.2651283 ]\n",
      " [ 0.2310241 ]\n",
      " [ 0.26336063]\n",
      " [ 0.15796183]\n",
      " [ 0.12476236]\n",
      " [ 0.26396675]\n",
      " [ 0.24311784]\n",
      " [ 0.22705307]\n",
      " [ 0.24531109]\n",
      " [ 0.25237847]\n",
      " [ 0.23740835]\n",
      " [ 0.21945012]\n",
      " [ 0.20172334]\n",
      " [ 0.221963  ]\n",
      " [ 0.26396675]\n",
      " [ 0.24017513]\n",
      " [ 0.23405811]\n",
      " [-0.00795384]\n",
      " [ 0.03742257]\n",
      " [ 0.25630202]\n",
      " [ 0.22687438]\n",
      " [ 0.00706419]\n",
      " [ 0.17392142]\n",
      " [ 0.17995971]\n",
      " [ 0.21920925]\n",
      " [ 0.22706765]\n",
      " [ 0.2640944 ]\n",
      " [ 0.22074594]\n",
      " [ 0.2245454 ]\n",
      " [ 0.13008639]\n",
      " [ 0.23373666]\n",
      " [ 0.03947932]\n",
      " [ 0.21614097]\n",
      " [ 0.21991179]\n",
      " [ 0.27244839]\n",
      " [ 0.16938527]\n",
      " [ 0.21169195]\n",
      " [ 0.17918299]\n",
      " [ 0.16678473]\n",
      " [ 0.13713522]\n",
      " [ 0.23290959]\n",
      " [ 0.27866774]\n",
      " [ 0.22549616]\n",
      " [ 0.18931944]\n",
      " [ 0.23380934]\n",
      " [ 0.26510221]\n",
      " [ 0.04053761]\n",
      " [ 0.20585268]\n",
      " [ 0.21299887]\n",
      " [ 0.26519014]\n",
      " [ 0.25539342]\n",
      " [ 0.17392142]\n",
      " [ 0.25413936]\n",
      " [ 0.23317953]\n",
      " [ 0.25394489]\n",
      " [ 0.25178893]\n",
      " [ 0.18147393]\n",
      " [ 0.26499525]\n",
      " [ 0.23271523]\n",
      " [ 0.17868018]\n",
      " [ 0.23278091]\n",
      " [ 0.21614592]\n",
      " [ 0.18568378]\n",
      " [ 0.20863845]\n",
      " [ 0.17840745]\n",
      " [ 0.19429984]\n",
      " [ 0.26043998]\n",
      " [ 0.26523746]\n",
      " [ 0.19683729]\n",
      " [ 0.26531786]\n",
      " [ 0.23259917]\n",
      " [ 0.23914329]\n",
      " [ 0.12496864]\n",
      " [ 0.22004721]\n",
      " [ 0.25440756]\n",
      " [ 0.22492249]\n",
      " [ 0.18128834]\n",
      " [ 0.25539342]\n",
      " [ 0.26304236]\n",
      " [ 0.26128815]\n",
      " [ 0.22457327]\n",
      " [ 0.1246246 ]\n",
      " [ 0.22188462]\n",
      " [ 0.2355323 ]\n",
      " [ 0.15787301]\n",
      " [ 0.20863845]\n",
      " [ 0.25859269]\n",
      " [ 0.26103585]\n",
      " [ 0.20591521]\n",
      " [ 0.2196428 ]\n",
      " [ 0.21015546]\n",
      " [ 0.22074594]\n",
      " [ 0.22687438]\n",
      " [ 0.23633364]\n",
      " [ 0.21672237]\n",
      " [ 0.23293336]\n",
      " [ 0.25985678]\n",
      " [ 0.25824849]\n",
      " [ 0.23851564]\n",
      " [ 0.22823681]\n",
      " [ 0.2523644 ]\n",
      " [ 0.26255409]\n",
      " [ 0.26552572]\n",
      " [ 0.26158377]\n",
      " [ 0.26472233]\n",
      " [ 0.25095478]\n",
      " [ 0.21685734]\n",
      " [ 0.17840745]\n",
      " [ 0.21614592]\n",
      " [ 0.18368439]\n",
      " [ 0.2330757 ]\n",
      " [ 0.24017513]\n",
      " [ 0.15787301]\n",
      " [ 0.2568129 ]\n",
      " [ 0.15744961]\n",
      " [ 0.23549366]\n",
      " [ 0.23782197]\n",
      " [ 0.25950825]\n",
      " [ 0.21927011]\n",
      " [ 0.23355433]\n",
      " [ 0.26246501]\n",
      " [ 0.16734852]\n",
      " [ 0.2247644 ]\n",
      " [ 0.26519014]\n",
      " [ 0.10777248]\n",
      " [ 0.21927011]\n",
      " [ 0.0983265 ]\n",
      " [ 0.23583045]\n",
      " [ 0.16938527]\n",
      " [ 0.22823681]\n",
      " [ 0.22784656]\n",
      " [ 0.16678473]\n",
      " [ 0.2196428 ]\n",
      " [ 0.221699  ]\n",
      " [ 0.221963  ]\n",
      " [ 0.27050973]\n",
      " [ 0.20482482]\n",
      " [ 0.13428584]\n",
      " [ 0.225247  ]\n",
      " [ 0.26553113]\n",
      " [ 0.26119866]]\n"
     ]
    }
   ],
   "source": [
    "# CHF = 1일때의 위험도\n",
    "print(h_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20611449]\n",
      " [ 0.25838684]\n",
      " [ 0.23056667]\n",
      " [ 0.25914378]\n",
      " [ 0.20832612]\n",
      " [ 0.26230175]\n",
      " [ 0.24578235]\n",
      " [ 0.19321058]\n",
      " [ 0.19789927]\n",
      " [ 0.19632049]\n",
      " [ 0.23431627]\n",
      " [ 0.17354517]\n",
      " [ 0.23865291]\n",
      " [ 0.19642306]\n",
      " [ 0.26205748]\n",
      " [ 0.18765745]\n",
      " [ 0.26475203]\n",
      " [ 0.26359217]\n",
      " [ 0.26403348]\n",
      " [ 0.21843096]\n",
      " [ 0.19215532]\n",
      " [ 0.17182632]\n",
      " [ 0.2054477 ]\n",
      " [ 0.03325892]\n",
      " [ 0.21499887]\n",
      " [ 0.21159909]\n",
      " [ 0.17710097]\n",
      " [ 0.26229072]\n",
      " [ 0.13994474]\n",
      " [ 0.25065264]\n",
      " [ 0.17585951]\n",
      " [ 0.25724475]\n",
      " [ 0.17710097]\n",
      " [ 0.16820507]\n",
      " [ 0.26359217]\n",
      " [ 0.26504827]\n",
      " [ 0.02182357]\n",
      " [ 0.26458879]\n",
      " [ 0.23322721]\n",
      " [ 0.17710097]\n",
      " [ 0.1978216 ]\n",
      " [ 0.23620828]\n",
      " [ 0.23854494]\n",
      " [ 0.2328919 ]\n",
      " [ 0.26491626]\n",
      " [ 0.23390204]\n",
      " [ 0.20324698]\n",
      " [ 0.18941321]\n",
      " [ 0.26085021]\n",
      " [ 0.2034006 ]\n",
      " [ 0.11097397]\n",
      " [-0.01288921]\n",
      " [ 0.23167735]\n",
      " [ 0.172928  ]\n",
      " [ 0.2568276 ]\n",
      " [ 0.23011221]\n",
      " [ 0.21824982]\n",
      " [ 0.23267597]\n",
      " [ 0.2149011 ]\n",
      " [ 0.20544008]\n",
      " [ 0.21736147]\n",
      " [ 0.20858632]\n",
      " [ 0.2568276 ]\n",
      " [ 0.20454242]\n",
      " [ 0.2440644 ]\n",
      " [ 0.25737009]\n",
      " [ 0.2505176 ]\n",
      " [ 0.2635181 ]\n",
      " [ 0.26503405]\n",
      " [ 0.26984199]\n",
      " [ 0.25376684]\n",
      " [ 0.22713297]\n",
      " [ 0.19380914]\n",
      " [ 0.21749878]\n",
      " [ 0.17489125]\n",
      " [ 0.19473102]\n",
      " [ 0.20793202]\n",
      " [ 0.10533163]\n",
      " [ 0.23269839]\n",
      " [ 0.25319296]\n",
      " [ 0.17182834]\n",
      " [ 0.13853914]\n",
      " [ 0.14538203]\n",
      " [ 0.16123757]\n",
      " [ 0.24578235]\n",
      " [ 0.20243837]\n",
      " [ 0.14602437]\n",
      " [ 0.18014484]\n",
      " [ 0.26515668]\n",
      " [ 0.21176163]\n",
      " [ 0.24732953]\n",
      " [ 0.1732863 ]\n",
      " [ 0.26458879]\n",
      " [ 0.22832755]\n",
      " [ 0.20049078]\n",
      " [ 0.20672026]\n",
      " [ 0.24268902]\n",
      " [ 0.23980682]\n",
      " [ 0.25981413]\n",
      " [ 0.20832612]\n",
      " [ 0.11099046]\n",
      " [ 0.15664333]\n",
      " [ 0.20611449]\n",
      " [ 0.25747732]\n",
      " [ 0.23533783]\n",
      " [ 0.19691586]\n",
      " [ 0.22882929]\n",
      " [ 0.1868883 ]\n",
      " [ 0.2635181 ]\n",
      " [ 0.23282811]\n",
      " [ 0.22992275]\n",
      " [ 0.22208948]\n",
      " [ 0.20889203]\n",
      " [ 0.20375768]\n",
      " [ 0.23358248]\n",
      " [ 0.2231984 ]\n",
      " [ 0.21937981]\n",
      " [ 0.20050592]\n",
      " [ 0.23037494]\n",
      " [ 0.24949002]\n",
      " [ 0.20967667]\n",
      " [ 0.15904724]\n",
      " [ 0.26515668]\n",
      " [ 0.1732863 ]\n",
      " [ 0.23523662]\n",
      " [ 0.20234197]\n",
      " [ 0.02741757]\n",
      " [ 0.203843  ]\n",
      " [ 0.2115765 ]\n",
      " [ 0.24111629]\n",
      " [ 0.26166733]\n",
      " [ 0.17335616]\n",
      " [ 0.11328723]\n",
      " [ 0.20117359]\n",
      " [ 0.24206737]\n",
      " [ 0.22208948]\n",
      " [ 0.26674652]\n",
      " [ 0.18100441]\n",
      " [ 0.22085864]\n",
      " [ 0.23428716]\n",
      " [ 0.23279034]\n",
      " [-0.01288921]\n",
      " [ 0.13328199]\n",
      " [ 0.23289575]\n",
      " [ 0.23340914]\n",
      " [ 0.20049078]\n",
      " [ 0.19443404]\n",
      " [ 0.18173907]\n",
      " [ 0.23282448]\n",
      " [ 0.25095872]\n",
      " [ 0.23309387]\n",
      " [ 0.26413241]\n",
      " [ 0.21895082]\n",
      " [ 0.22774264]\n",
      " [ 0.2115765 ]\n",
      " [ 0.25914378]\n",
      " [ 0.25360109]\n",
      " [ 0.26317439]\n",
      " [ 0.17646848]\n",
      " [ 0.21306129]\n",
      " [ 0.18173907]\n",
      " [ 0.2339277 ]\n",
      " [ 0.14077422]\n",
      " [ 0.25797588]\n",
      " [ 0.26143408]\n",
      " [ 0.21254831]\n",
      " [ 0.04101824]\n",
      " [ 0.24319308]\n",
      " [-0.00938622]\n",
      " [ 0.17710097]\n",
      " [ 0.23289149]\n",
      " [ 0.23414591]\n",
      " [ 0.13444288]\n",
      " [ 0.211481  ]\n",
      " [ 0.14037381]\n",
      " [ 0.19173996]\n",
      " [-0.00573403]\n",
      " [ 0.23267232]\n",
      " [ 0.22674131]\n",
      " [ 0.17182834]\n",
      " [ 0.17335925]\n",
      " [ 0.19632049]\n",
      " [ 0.23725158]\n",
      " [ 0.22295934]\n",
      " [ 0.21834998]\n",
      " [ 0.25561202]\n",
      " [ 0.21265598]\n",
      " [ 0.26392706]\n",
      " [ 0.23037494]\n",
      " [ 0.25981413]\n",
      " [ 0.15839651]\n",
      " [ 0.13328199]\n",
      " [ 0.26114674]\n",
      " [ 0.24302734]\n",
      " [ 0.22543693]\n",
      " [ 0.23822197]\n",
      " [ 0.23589956]\n",
      " [ 0.23456266]\n",
      " [ 0.20133325]\n",
      " [ 0.20454242]\n",
      " [ 0.20611449]\n",
      " [ 0.26114674]\n",
      " [ 0.23980682]\n",
      " [ 0.23014075]\n",
      " [-0.00845787]\n",
      " [ 0.0357919 ]\n",
      " [ 0.24294529]\n",
      " [ 0.20858632]\n",
      " [ 0.01514962]\n",
      " [ 0.17102476]\n",
      " [ 0.17212507]\n",
      " [ 0.211481  ]\n",
      " [ 0.22568735]\n",
      " [ 0.21722182]\n",
      " [ 0.2054477 ]\n",
      " [ 0.22010773]\n",
      " [ 0.13853914]\n",
      " [ 0.2249152 ]\n",
      " [ 0.03325892]\n",
      " [ 0.19566077]\n",
      " [ 0.21244895]\n",
      " [ 0.2607606 ]\n",
      " [ 0.16359923]\n",
      " [ 0.19510005]\n",
      " [ 0.18068128]\n",
      " [ 0.1611781 ]\n",
      " [ 0.1439184 ]\n",
      " [ 0.23274186]\n",
      " [ 0.27426183]\n",
      " [ 0.22207795]\n",
      " [ 0.18754152]\n",
      " [ 0.23308042]\n",
      " [ 0.26386106]\n",
      " [ 0.04105422]\n",
      " [ 0.19498602]\n",
      " [ 0.19789927]\n",
      " [ 0.26408421]\n",
      " [ 0.23056667]\n",
      " [ 0.17102476]\n",
      " [ 0.24050207]\n",
      " [ 0.23284229]\n",
      " [ 0.24578235]\n",
      " [ 0.24368713]\n",
      " [ 0.17260404]\n",
      " [ 0.26359217]\n",
      " [ 0.2326703 ]\n",
      " [ 0.15664333]\n",
      " [ 0.23269447]\n",
      " [ 0.22580827]\n",
      " [ 0.18014484]\n",
      " [ 0.20147935]\n",
      " [ 0.1731146 ]\n",
      " [ 0.19642306]\n",
      " [ 0.25439431]\n",
      " [ 0.26420511]\n",
      " [ 0.19858249]\n",
      " [ 0.26453633]\n",
      " [ 0.23256574]\n",
      " [ 0.22775992]\n",
      " [ 0.12370222]\n",
      " [ 0.20740934]\n",
      " [ 0.24627042]\n",
      " [ 0.22085864]\n",
      " [ 0.1737442 ]\n",
      " [ 0.23056667]\n",
      " [ 0.25914378]\n",
      " [ 0.25577108]\n",
      " [ 0.2115765 ]\n",
      " [ 0.12349873]\n",
      " [ 0.20967667]\n",
      " [ 0.20965576]\n",
      " [ 0.15144052]\n",
      " [ 0.20147935]\n",
      " [ 0.23620828]\n",
      " [ 0.24484369]\n",
      " [ 0.19291252]\n",
      " [ 0.21209063]\n",
      " [ 0.20270022]\n",
      " [ 0.2054477 ]\n",
      " [ 0.20858632]\n",
      " [ 0.23011221]\n",
      " [ 0.20377465]\n",
      " [ 0.23275074]\n",
      " [ 0.23424847]\n",
      " [ 0.25623265]\n",
      " [ 0.20362521]\n",
      " [ 0.2125848 ]\n",
      " [ 0.22882929]\n",
      " [ 0.25815226]\n",
      " [ 0.2649529 ]\n",
      " [ 0.25630703]\n",
      " [ 0.2629192 ]\n",
      " [ 0.23758273]\n",
      " [ 0.19505274]\n",
      " [ 0.1731146 ]\n",
      " [ 0.22580827]\n",
      " [ 0.17646848]\n",
      " [ 0.23280356]\n",
      " [ 0.23980682]\n",
      " [ 0.15144052]\n",
      " [ 0.24906545]\n",
      " [ 0.15745113]\n",
      " [ 0.23374746]\n",
      " [ 0.23474747]\n",
      " [ 0.25282129]\n",
      " [ 0.21159909]\n",
      " [ 0.23298338]\n",
      " [ 0.25797588]\n",
      " [ 0.16123757]\n",
      " [ 0.2074516 ]\n",
      " [ 0.26408421]\n",
      " [ 0.11075165]\n",
      " [ 0.21159909]\n",
      " [ 0.0655156 ]\n",
      " [ 0.2338846 ]\n",
      " [ 0.16359923]\n",
      " [ 0.2125848 ]\n",
      " [ 0.2267284 ]\n",
      " [ 0.1611781 ]\n",
      " [ 0.21209063]\n",
      " [ 0.21176163]\n",
      " [ 0.20611449]\n",
      " [ 0.25379803]\n",
      " [ 0.20060202]\n",
      " [ 0.14077422]\n",
      " [ 0.22157659]\n",
      " [ 0.26496738]\n",
      " [ 0.25561202]]\n"
     ]
    }
   ],
   "source": [
    "# CHF = 0일때의 위험도\n",
    "print(h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.01597476]\n",
      " [1.00429395]\n",
      " [1.0251375 ]\n",
      " [1.00390619]\n",
      " [1.0091864 ]\n",
      " [1.00216593]\n",
      " [1.00819594]\n",
      " [1.02579882]\n",
      " [1.01521417]\n",
      " [1.04852878]\n",
      " [1.0025328 ]\n",
      " [1.00798856]\n",
      " [1.0160224 ]\n",
      " [0.99787903]\n",
      " [1.00230705]\n",
      " [1.02211725]\n",
      " [1.00069914]\n",
      " [1.00140406]\n",
      " [1.02036071]\n",
      " [1.00604082]\n",
      " [1.00798299]\n",
      " [1.00754229]\n",
      " [1.01541586]\n",
      " [1.00623978]\n",
      " [1.02583471]\n",
      " [1.00770052]\n",
      " [1.00707564]\n",
      " [1.00217233]\n",
      " [1.01102378]\n",
      " [1.00739246]\n",
      " [1.00746023]\n",
      " [1.00485481]\n",
      " [1.00707564]\n",
      " [1.00768496]\n",
      " [1.00140406]\n",
      " [1.00051352]\n",
      " [1.0326276 ]\n",
      " [1.00073426]\n",
      " [1.00096274]\n",
      " [1.00707564]\n",
      " [1.04078582]\n",
      " [1.02263682]\n",
      " [1.00964499]\n",
      " [1.00042012]\n",
      " [1.00059566]\n",
      " [1.00197115]\n",
      " [1.02873616]\n",
      " [1.01816512]\n",
      " [1.00298908]\n",
      " [1.02580148]\n",
      " [0.99526763]\n",
      " [1.00247493]\n",
      " [1.00962037]\n",
      " [1.00540604]\n",
      " [1.00505219]\n",
      " [1.00624082]\n",
      " [1.02238392]\n",
      " [1.00005481]\n",
      " [0.99921388]\n",
      " [1.02564206]\n",
      " [1.007258  ]\n",
      " [1.01845631]\n",
      " [1.00505219]\n",
      " [0.99718489]\n",
      " [1.00496912]\n",
      " [1.00479487]\n",
      " [1.0071794 ]\n",
      " [1.0144989 ]\n",
      " [1.000522  ]\n",
      " [1.01924002]\n",
      " [1.00636267]\n",
      " [1.00113519]\n",
      " [1.0141819 ]\n",
      " [1.00599128]\n",
      " [1.05320444]\n",
      " [1.00744553]\n",
      " [1.03496125]\n",
      " [0.99850795]\n",
      " [1.00043318]\n",
      " [1.00653309]\n",
      " [1.00769672]\n",
      " [0.99158287]\n",
      " [1.01116024]\n",
      " [1.00612966]\n",
      " [1.00819594]\n",
      " [1.00977716]\n",
      " [1.01130558]\n",
      " [1.0055543 ]\n",
      " [1.00044579]\n",
      " [1.00998691]\n",
      " [1.00806855]\n",
      " [1.00808308]\n",
      " [1.00073426]\n",
      " [1.01733722]\n",
      " [1.00497996]\n",
      " [1.01810443]\n",
      " [1.0139097 ]\n",
      " [1.00036837]\n",
      " [1.00355279]\n",
      " [1.0091864 ]\n",
      " [1.00193775]\n",
      " [1.02228145]\n",
      " [1.01597476]\n",
      " [1.0047431 ]\n",
      " [1.00376513]\n",
      " [1.00278177]\n",
      " [1.02381425]\n",
      " [1.0206424 ]\n",
      " [1.0144989 ]\n",
      " [1.0003135 ]\n",
      " [0.99855299]\n",
      " [1.01947646]\n",
      " [1.00884414]\n",
      " [1.00727678]\n",
      " [1.00505053]\n",
      " [1.01850916]\n",
      " [1.00714909]\n",
      " [1.00463597]\n",
      " [1.00064937]\n",
      " [1.007685  ]\n",
      " [1.01228277]\n",
      " [0.99899662]\n",
      " [1.00044579]\n",
      " [1.00808308]\n",
      " [1.00365235]\n",
      " [1.00996134]\n",
      " [1.00748867]\n",
      " [1.00730469]\n",
      " [1.01308159]\n",
      " [1.0076095 ]\n",
      " [1.00253195]\n",
      " [1.00908425]\n",
      " [1.00057531]\n",
      " [1.00723111]\n",
      " [1.0140649 ]\n",
      " [1.01947646]\n",
      " [1.01674321]\n",
      " [1.00931338]\n",
      " [1.00407212]\n",
      " [1.00249367]\n",
      " [1.00024981]\n",
      " [1.00247493]\n",
      " [0.99151655]\n",
      " [1.00042652]\n",
      " [1.00124492]\n",
      " [1.00497996]\n",
      " [1.01090993]\n",
      " [1.00851777]\n",
      " [1.00030737]\n",
      " [1.01998972]\n",
      " [1.00075052]\n",
      " [1.00106026]\n",
      " [1.00569028]\n",
      " [1.0149101 ]\n",
      " [1.01308159]\n",
      " [1.00390619]\n",
      " [1.00642027]\n",
      " [1.01713327]\n",
      " [1.007242  ]\n",
      " [1.00728455]\n",
      " [1.00851777]\n",
      " [1.00206307]\n",
      " [0.99353262]\n",
      " [1.00449922]\n",
      " [1.00265509]\n",
      " [1.02133859]\n",
      " [1.06128511]\n",
      " [1.02043265]\n",
      " [1.00093036]\n",
      " [1.00707564]\n",
      " [1.00041944]\n",
      " [1.00230593]\n",
      " [0.99077665]\n",
      " [1.0077582 ]\n",
      " [1.03301012]\n",
      " [1.00919907]\n",
      " [0.999226  ]\n",
      " [1.00004838]\n",
      " [1.0012682 ]\n",
      " [1.00769672]\n",
      " [1.00836753]\n",
      " [1.04852878]\n",
      " [1.01013572]\n",
      " [1.00098912]\n",
      " [1.03737892]\n",
      " [1.00560228]\n",
      " [1.02496028]\n",
      " [1.00120196]\n",
      " [1.00064937]\n",
      " [1.00355279]\n",
      " [0.99956541]\n",
      " [0.99151655]\n",
      " [1.00282399]\n",
      " [1.0000905 ]\n",
      " [1.00161745]\n",
      " [1.00711431]\n",
      " [1.01661544]\n",
      " [1.00284975]\n",
      " [1.01828198]\n",
      " [0.99718489]\n",
      " [1.01597476]\n",
      " [1.00282399]\n",
      " [1.00036837]\n",
      " [1.00392505]\n",
      " [1.00050416]\n",
      " [1.001632  ]\n",
      " [1.01344633]\n",
      " [1.01845631]\n",
      " [0.99194717]\n",
      " [1.00290086]\n",
      " [1.00786541]\n",
      " [1.0077582 ]\n",
      " [1.00138125]\n",
      " [1.04798847]\n",
      " [1.01541586]\n",
      " [1.00444753]\n",
      " [0.99158287]\n",
      " [1.00886049]\n",
      " [1.00623978]\n",
      " [1.02069136]\n",
      " [1.00749076]\n",
      " [1.01175636]\n",
      " [1.00580281]\n",
      " [1.01673031]\n",
      " [0.99850284]\n",
      " [1.00562238]\n",
      " [0.99323978]\n",
      " [1.00016774]\n",
      " [1.00441563]\n",
      " [1.00342406]\n",
      " [1.0017795 ]\n",
      " [1.00072919]\n",
      " [1.00124192]\n",
      " [0.99948353]\n",
      " [1.01092592]\n",
      " [1.01521417]\n",
      " [1.00110654]\n",
      " [1.0251375 ]\n",
      " [1.00290086]\n",
      " [1.0137307 ]\n",
      " [1.00033729]\n",
      " [1.00819594]\n",
      " [1.00813472]\n",
      " [1.00890934]\n",
      " [1.00140406]\n",
      " [1.00004494]\n",
      " [1.02228145]\n",
      " [1.00008644]\n",
      " [0.99038417]\n",
      " [1.0055543 ]\n",
      " [1.00718479]\n",
      " [1.00530688]\n",
      " [0.99787903]\n",
      " [1.00606397]\n",
      " [1.00103288]\n",
      " [0.99825632]\n",
      " [1.00078183]\n",
      " [1.00003343]\n",
      " [1.0114484 ]\n",
      " [1.00126722]\n",
      " [1.01271807]\n",
      " [1.00817033]\n",
      " [1.00407212]\n",
      " [1.00757267]\n",
      " [1.0251375 ]\n",
      " [1.00390619]\n",
      " [1.00553232]\n",
      " [1.01308159]\n",
      " [1.00112651]\n",
      " [1.01228277]\n",
      " [1.02621424]\n",
      " [1.00645323]\n",
      " [1.00718479]\n",
      " [1.02263682]\n",
      " [1.01632397]\n",
      " [1.01308758]\n",
      " [1.00758077]\n",
      " [1.00748309]\n",
      " [1.01541586]\n",
      " [1.01845631]\n",
      " [1.00624082]\n",
      " [1.0130319 ]\n",
      " [1.00018264]\n",
      " [1.02593902]\n",
      " [1.00201787]\n",
      " [1.03550625]\n",
      " [1.01577514]\n",
      " [1.02381425]\n",
      " [1.00441153]\n",
      " [1.00057299]\n",
      " [1.00529068]\n",
      " [1.00180475]\n",
      " [1.01346186]\n",
      " [1.02204406]\n",
      " [1.00530688]\n",
      " [0.99038417]\n",
      " [1.007242  ]\n",
      " [1.00027217]\n",
      " [1.00036837]\n",
      " [1.00645323]\n",
      " [1.00777754]\n",
      " [0.99999848]\n",
      " [1.00174772]\n",
      " [1.00307924]\n",
      " [1.00670936]\n",
      " [1.00770052]\n",
      " [1.00057112]\n",
      " [1.00449922]\n",
      " [1.00612966]\n",
      " [1.01746354]\n",
      " [1.00110654]\n",
      " [0.99702527]\n",
      " [1.00770052]\n",
      " [1.03335512]\n",
      " [1.00194774]\n",
      " [1.00580281]\n",
      " [1.01577514]\n",
      " [1.00111878]\n",
      " [1.00562238]\n",
      " [1.00758077]\n",
      " [1.00998691]\n",
      " [1.01597476]\n",
      " [1.01685212]\n",
      " [1.00423173]\n",
      " [0.99353262]\n",
      " [1.00367716]\n",
      " [1.00056391]\n",
      " [1.00560228]]\n"
     ]
    }
   ],
   "source": [
    "#CHF=1 - CHF=0\n",
    "print(np.exp(rec_trt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  1.4689153427960906\n",
      "SE :  [0.02458144]\n",
      "95% CI :  (array([1.42055763]), array([1.51727306]))\n"
     ]
    }
   ],
   "source": [
    "x_trt = numpy.copy(test_dataset['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,4] = 1 \n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,4] = 0\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(test_dataset['x'], 1, 0, 4)\n",
    "\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.6892878557901049}\n",
      "Test metrics: {'c_index': 0.6891832992665624, 'c_index_bootstrap': {'mean': 0.6881813636498676, 'confidence_interval': (0.6850514650164563, 0.6913112622832789)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0004991066534650134, \n",
    "              \"dropout\": 0.0783935546875, \n",
    "              \"lr_decay\": 0.000746533203125, \n",
    "              \"momentum\": 0.8255483398437501, \n",
    "              \"L2_reg\": 1.5917993164062498, \n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 7, \n",
    "              \"hidden_layers_sizes\": [20, 20, 20], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/gbsg_cancer_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 1200,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.6907473299044762}\n",
      "Test metrics: {'c_index': 0.6889353132138992, 'c_index_bootstrap': {'mean': 0.692478007995837, 'confidence_interval': (0.6895169642310882, 0.6954390517605858)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0004991066534650134, \n",
    "              \"dropout\": 0.0783935546875, \n",
    "              \"lr_decay\": 0.000746533203125, \n",
    "              \"momentum\": 0.8255483398437501, \n",
    "              \"L2_reg\": 1.5917993164062498, \n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 7, \n",
    "              \"hidden_layers_sizes\": [20, 20, 20], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/gbsg_cancer_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 1200,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating treatment recommendation survival curvs\n",
      "Recommending treatments: [-0.5299654  1.886927 ]\n",
      "Printing treatment recommendation metrics\n",
      "Recommendation metrics: {'rec_median': 40.098564, 'antirec_median': 31.770021}\n",
      "C:/Users/ASUS/Dropbox/석사학위논문/model_pathtrt_plot.pdf\n",
      "rec median :  66.29979705810547\n",
      "Non-rec median :  50.20123291015625\n",
      "<lifelines.StatisticalResult>\n",
      "               t_0 = -1\n",
      " null_distribution = chi squared\n",
      "degrees_of_freedom = 1\n",
      "             alpha = 0.95\n",
      "\n",
      "---\n",
      " test_statistic      p  -log2(p)\n",
      "           8.56 <0.005      8.19\n",
      "p-value :  0.0034272822647458657\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "treatment_idx = 0\n",
    "results_dir = 'C:/Users/ASUS/Dropbox/석사학위논문/model_path'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/gbsg_cancer_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "    \n",
    "    if 'test' in datasets and treatment_idx is not None:\n",
    "        print(\"Calculating treatment recommendation survival curvs\")\n",
    "        \n",
    "        # We use the test dataset because these experiments don't have a viz dataset\n",
    "        save_treatment_rec_visualizations(model, test_dataset, output_dir=results_dir, \n",
    "            trt_idx = treatment_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating treatment recommendation survival curvs\n",
      "Recommending treatments: [-0.5299654  1.886927 ]\n",
      "Printing treatment recommendation metrics\n",
      "Recommendation metrics: {'rec_median': 40.098564, 'antirec_median': 31.770021}\n",
      "C:/Users/ASUS/Dropbox/석사학위논문/model_pathtrt_plot.pdf\n",
      "rec median :  66.29979705810547\n",
      "Non-rec median :  50.20123291015625\n",
      "<lifelines.StatisticalResult>\n",
      "               t_0 = -1\n",
      " null_distribution = chi squared\n",
      "degrees_of_freedom = 1\n",
      "             alpha = 0.95\n",
      "\n",
      "---\n",
      " test_statistic      p  -log2(p)\n",
      "           8.56 <0.005      8.19\n",
      "p-value :  0.0034272822647458657\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "treatment_idx = 0\n",
    "results_dir = 'C:/Users/ASUS/Dropbox/석사학위논문/model_path'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/gbsg_cancer_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "    \n",
    "    if 'test' in datasets and treatment_idx is not None:\n",
    "        print(\"Calculating treatment recommendation survival curvs\")\n",
    "        \n",
    "        # We use the test dataset because these experiments don't have a viz dataset\n",
    "        save_treatment_rec_visualizations(model, test_dataset, output_dir=results_dir, \n",
    "            trt_idx = treatment_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "추천된 trt와 실제 trt가 일치하는 환자들에 대한 생존 곡선과\n",
    "추천된 trt와 실제 trt가 불일치 하는 환자들에 대한 생존 곡선의 차이가 유의하다.\n",
    "즉, 모형의 추천대로 trt를 받은 환자는 그렇지 못한 환자들에 비해 더 오래 살았다.\n",
    "따라서 모형의 trt 예측이 통계적으로 올바른 예측이 된다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min :  0.2942272530386598\n",
      "1분위수 :  0.5565689210906419\n",
      "중앙값 :  0.818760874974022\n",
      "3분위수 :  0.9503914375992975\n",
      "max :  1.9000122192036957\n",
      "평균 :  0.7161766383971048\n",
      "표준편차 :  1.404735922638979\n"
     ]
    }
   ],
   "source": [
    "#각 개별 환자의 trt별 효과 차이\n",
    "rec_trt = model.recommend_treatment(datasets['test']['x'], 1, 0, 0)\n",
    "print('min : ',np.exp(np.min(rec_trt)))\n",
    "print('1분위수 : ',np.exp(np.percentile(rec_trt, 25)))\n",
    "print('중앙값 : ',np.exp(np.median(rec_trt)))\n",
    "print('3분위수 : ',np.exp(np.percentile(rec_trt, 75)))\n",
    "print('max : ',np.exp(np.max(rec_trt)))\n",
    "print('평균 : ',np.exp(np.mean(rec_trt)))\n",
    "print('표준편차 : ',np.exp(np.std(rec_trt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  0.8811286717609781\n",
      "SE :  [0.00484054]\n",
      "95% CI :  (array([0.8716246]), array([0.89063274]))\n"
     ]
    }
   ],
   "source": [
    "x_trt = numpy.copy(test_dataset['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,0] = 1 \n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,0] = 0\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(test_dataset['x'], 1, 0, 0)\n",
    "\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METABRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.677714616409068}\n",
      "Test metrics: {'c_index': 0.639087166118387, 'c_index_bootstrap': {'mean': 0.6388228303044652, 'confidence_interval': (0.634113758687543, 0.6435319019213873)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0020065103592061526, \n",
    "              \"dropout\": 0.034404296875000004, \n",
    "              \"lr_decay\": 0.00055220703125, \n",
    "              \"momentum\": 0.8109013671875, \n",
    "              \"L2_reg\": 4.6593974609375,\n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 9, \n",
    "              \"hidden_layers_sizes\": [42, 42, 42], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/metabric_IHC4_clinical_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 100,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.6683277955500707}\n",
      "Test metrics: {'c_index': 0.6437216808391782, 'c_index_bootstrap': {'mean': 0.6445820998413789, 'confidence_interval': (0.641063713018568, 0.6481004866641898)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0020065103592061526, \n",
    "              \"dropout\": 0.34404296875000004, \n",
    "              \"lr_decay\": 0.00055220703125, \n",
    "              \"momentum\": 0.8109013671875, \n",
    "              \"L2_reg\": 4.6593974609375,\n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 9, \n",
    "              \"hidden_layers_sizes\": [42, 42, 42], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/metabric_IHC4_clinical_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 100,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min :  0.9996152551328391\n",
      "1분위수 :  0.9998339500011345\n",
      "중앙값 :  0.9998786317257972\n",
      "3분위수 :  0.9999280202280008\n",
      "max :  1.0002416093472866\n",
      "평균 :  0.9998906542175069\n",
      "표준편차 :  1.0000854750771593\n"
     ]
    }
   ],
   "source": [
    "#각 개별 환자의 trt별 효과 차이\n",
    "rec_trt = model.recommend_treatment(datasets['test']['x'], 1, 0, 6)\n",
    "print('min : ',np.exp(np.min(rec_trt)))\n",
    "print('1분위수 : ',np.exp(np.percentile(rec_trt, 25)))\n",
    "print('중앙값 : ',np.exp(np.median(rec_trt)))\n",
    "print('3분위수 : ',np.exp(np.percentile(rec_trt, 75)))\n",
    "print('max : ',np.exp(np.max(rec_trt)))\n",
    "print('평균 : ',np.exp(np.mean(rec_trt)))\n",
    "print('표준편차 : ',np.exp(np.std(rec_trt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trt = numpy.copy(datasets['test']['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,6] = 1 #화학요법 받음\n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,6] = 0 #화학요법 안받음\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(test_data['x'], 1, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.61635619]\n",
      " [1.63079248]\n",
      " [1.63448682]\n",
      " [1.63307357]\n",
      " [1.64050375]\n",
      " [1.63943947]\n",
      " [1.63904229]\n",
      " [1.63818039]\n",
      " [1.63882814]\n",
      " [1.63724335]\n",
      " [1.63414442]\n",
      " [1.63538694]\n",
      " [1.63384147]\n",
      " [1.63066515]\n",
      " [1.63304444]\n",
      " [1.63997025]\n",
      " [1.63848572]\n",
      " [1.63628431]\n",
      " [1.6383697 ]\n",
      " [1.63867343]\n",
      " [1.63773017]\n",
      " [1.63323953]\n",
      " [1.61570368]\n",
      " [1.63827027]\n",
      " [1.63810594]\n",
      " [1.63551443]\n",
      " [1.63815199]\n",
      " [1.63735835]\n",
      " [1.63359621]\n",
      " [1.63078497]\n",
      " [1.63404612]\n",
      " [1.61036352]\n",
      " [1.62690913]\n",
      " [1.63893304]\n",
      " [1.63929034]\n",
      " [1.63888899]\n",
      " [1.62703874]\n",
      " [1.63909705]\n",
      " [1.63771467]\n",
      " [1.63073867]\n",
      " [1.63304125]\n",
      " [1.63381122]\n",
      " [1.63609382]\n",
      " [1.62685149]\n",
      " [1.62155198]\n",
      " [1.63918594]\n",
      " [1.62846554]\n",
      " [1.6361712 ]\n",
      " [1.63235537]\n",
      " [1.61658937]\n",
      " [1.6329211 ]\n",
      " [1.62387031]\n",
      " [1.63869703]\n",
      " [1.63730491]\n",
      " [1.63320391]\n",
      " [1.63804818]\n",
      " [1.63359554]\n",
      " [1.63454219]\n",
      " [1.63314212]\n",
      " [1.63996467]\n",
      " [1.63150933]\n",
      " [1.63278111]\n",
      " [1.62271766]\n",
      " [1.62455216]\n",
      " [1.63544067]\n",
      " [1.63491613]\n",
      " [1.63799759]\n",
      " [1.63904968]\n",
      " [1.63519201]\n",
      " [1.63720016]\n",
      " [1.63014949]\n",
      " [1.63628165]\n",
      " [1.63878478]\n",
      " [1.62906163]\n",
      " [1.63974443]\n",
      " [1.63764086]\n",
      " [1.63928322]\n",
      " [1.63743053]\n",
      " [1.6302857 ]\n",
      " [1.63579219]\n",
      " [1.6368778 ]\n",
      " [1.60740418]\n",
      " [1.63709515]\n",
      " [1.63670091]\n",
      " [1.63945035]\n",
      " [1.63773512]\n",
      " [1.63572756]\n",
      " [1.63300269]\n",
      " [1.60447522]\n",
      " [1.63036567]\n",
      " [1.63316777]\n",
      " [1.63966106]\n",
      " [1.6371576 ]\n",
      " [1.63650004]\n",
      " [1.63745634]\n",
      " [1.63582772]\n",
      " [1.63905884]\n",
      " [1.62791218]\n",
      " [1.63704802]\n",
      " [1.63800169]\n",
      " [1.63509851]\n",
      " [1.63619439]\n",
      " [1.63268481]\n",
      " [1.61287881]\n",
      " [1.6073864 ]\n",
      " [1.63456432]\n",
      " [1.63325748]\n",
      " [1.63906272]\n",
      " [1.63971371]\n",
      " [1.61658895]\n",
      " [1.6343266 ]\n",
      " [1.63187698]\n",
      " [1.6292138 ]\n",
      " [1.63443333]\n",
      " [1.63822138]\n",
      " [1.63239664]\n",
      " [1.63820953]\n",
      " [1.63830273]\n",
      " [1.6247064 ]\n",
      " [1.63174601]\n",
      " [1.63774768]\n",
      " [1.63273234]\n",
      " [1.63506247]\n",
      " [1.63705845]\n",
      " [1.63606223]\n",
      " [1.63055794]\n",
      " [1.60082429]\n",
      " [1.63822869]\n",
      " [1.63184716]\n",
      " [1.63134247]\n",
      " [1.62065642]\n",
      " [1.63922911]\n",
      " [1.63711474]\n",
      " [1.6346721 ]\n",
      " [1.62086322]\n",
      " [1.63835043]\n",
      " [1.6370457 ]\n",
      " [1.6371605 ]\n",
      " [1.63593819]\n",
      " [1.63904674]\n",
      " [1.63701982]\n",
      " [1.63290272]\n",
      " [1.63334936]\n",
      " [1.6376982 ]\n",
      " [1.63626228]\n",
      " [1.63899129]\n",
      " [1.63477616]\n",
      " [1.63805456]\n",
      " [1.63848029]\n",
      " [1.63106128]\n",
      " [1.6272655 ]\n",
      " [1.63800703]\n",
      " [1.64022704]\n",
      " [1.63786766]\n",
      " [1.63653165]\n",
      " [1.6338738 ]\n",
      " [1.62669829]\n",
      " [1.63567976]\n",
      " [1.63557963]\n",
      " [1.63454349]\n",
      " [1.63947687]\n",
      " [1.63376508]\n",
      " [1.63790588]\n",
      " [1.6321774 ]\n",
      " [1.63694438]\n",
      " [1.63616263]\n",
      " [1.63846943]\n",
      " [1.63923462]\n",
      " [1.63534927]\n",
      " [1.62582789]\n",
      " [1.63896114]\n",
      " [1.63644888]\n",
      " [1.63773824]\n",
      " [1.62693013]\n",
      " [1.62148131]\n",
      " [1.63880587]\n",
      " [1.63948272]\n",
      " [1.63684503]\n",
      " [1.63521831]\n",
      " [1.63856774]\n",
      " [1.6353533 ]\n",
      " [1.63450659]\n",
      " [1.63125613]\n",
      " [1.63935505]\n",
      " [1.63452684]\n",
      " [1.62500412]\n",
      " [1.63682261]\n",
      " [1.63903865]\n",
      " [1.63862302]\n",
      " [1.63870535]\n",
      " [1.63556586]\n",
      " [1.63817572]\n",
      " [1.62056513]\n",
      " [1.63676589]\n",
      " [1.6384642 ]\n",
      " [1.62871238]\n",
      " [1.63555922]\n",
      " [1.64024087]\n",
      " [1.63469159]\n",
      " [1.6285887 ]\n",
      " [1.63736505]\n",
      " [1.63024519]\n",
      " [1.6325215 ]\n",
      " [1.63541936]\n",
      " [1.63591838]\n",
      " [1.63520874]\n",
      " [1.63298798]\n",
      " [1.62459626]\n",
      " [1.62405231]\n",
      " [1.63894728]\n",
      " [1.61984699]\n",
      " [1.63973265]\n",
      " [1.63832547]\n",
      " [1.62984671]\n",
      " [1.638187  ]\n",
      " [1.63499802]\n",
      " [1.63915621]\n",
      " [1.63621803]\n",
      " [1.62918751]\n",
      " [1.61568988]\n",
      " [1.63827574]\n",
      " [1.63742874]\n",
      " [1.64041474]\n",
      " [1.63037039]\n",
      " [1.63525039]\n",
      " [1.61613778]\n",
      " [1.63808324]\n",
      " [1.6385746 ]\n",
      " [1.63812882]\n",
      " [1.63982664]\n",
      " [1.62888442]\n",
      " [1.63948712]\n",
      " [1.64003689]\n",
      " [1.63770059]\n",
      " [1.63777218]\n",
      " [1.63508667]\n",
      " [1.63892518]\n",
      " [1.62370997]\n",
      " [1.61722978]\n",
      " [1.63383956]\n",
      " [1.63541076]\n",
      " [1.63840012]\n",
      " [1.63572276]\n",
      " [1.64033768]\n",
      " [1.63527298]\n",
      " [1.63977216]\n",
      " [1.63244039]\n",
      " [1.63833608]\n",
      " [1.6325228 ]\n",
      " [1.62364094]\n",
      " [1.6097552 ]\n",
      " [1.63304791]\n",
      " [1.63603332]\n",
      " [1.6361309 ]\n",
      " [1.63687613]\n",
      " [1.63972587]\n",
      " [1.63665826]\n",
      " [1.63370415]\n",
      " [1.63877567]\n",
      " [1.63417097]\n",
      " [1.62512116]\n",
      " [1.63639221]\n",
      " [1.6388574 ]\n",
      " [1.63685883]\n",
      " [1.63296383]\n",
      " [1.63129676]\n",
      " [1.63823127]\n",
      " [1.63354523]\n",
      " [1.6332668 ]\n",
      " [1.63958448]\n",
      " [1.63797808]\n",
      " [1.63627942]\n",
      " [1.62709961]\n",
      " [1.63758288]\n",
      " [1.63554195]\n",
      " [1.63834316]\n",
      " [1.626934  ]\n",
      " [1.6394302 ]\n",
      " [1.63230999]\n",
      " [1.6401027 ]\n",
      " [1.63757215]\n",
      " [1.62415625]\n",
      " [1.6274386 ]\n",
      " [1.62643894]\n",
      " [1.63943814]\n",
      " [1.63813044]\n",
      " [1.63365496]\n",
      " [1.63853456]\n",
      " [1.63621113]\n",
      " [1.63578797]\n",
      " [1.63384845]\n",
      " [1.63739175]\n",
      " [1.63740948]\n",
      " [1.63917499]\n",
      " [1.63574372]\n",
      " [1.64051626]\n",
      " [1.63888632]\n",
      " [1.63647923]\n",
      " [1.63817671]\n",
      " [1.63388706]\n",
      " [1.63317293]\n",
      " [1.63744358]\n",
      " [1.63857909]\n",
      " [1.63534285]\n",
      " [1.63642989]\n",
      " [1.64061036]\n",
      " [1.63161426]\n",
      " [1.64072511]\n",
      " [1.63972731]\n",
      " [1.62546311]\n",
      " [1.6371254 ]\n",
      " [1.64017007]\n",
      " [1.62359698]\n",
      " [1.63939216]\n",
      " [1.63893023]\n",
      " [1.63893479]\n",
      " [1.63514125]\n",
      " [1.62937991]\n",
      " [1.63876307]\n",
      " [1.63263965]\n",
      " [1.63831681]\n",
      " [1.63203582]\n",
      " [1.63905381]\n",
      " [1.63965521]\n",
      " [1.63035271]\n",
      " [1.63645952]\n",
      " [1.63473434]\n",
      " [1.63925794]\n",
      " [1.63521416]\n",
      " [1.63686988]\n",
      " [1.63583939]\n",
      " [1.62716331]\n",
      " [1.63679148]\n",
      " [1.63936299]\n",
      " [1.63623825]\n",
      " [1.6071576 ]\n",
      " [1.6376576 ]\n",
      " [1.63224975]\n",
      " [1.62110846]\n",
      " [1.63781252]\n",
      " [1.63529604]\n",
      " [1.63752178]\n",
      " [1.63866972]\n",
      " [1.63697465]\n",
      " [1.63917114]\n",
      " [1.63375305]\n",
      " [1.63807013]\n",
      " [1.61511518]\n",
      " [1.63573701]\n",
      " [1.63468111]\n",
      " [1.6389791 ]\n",
      " [1.64028503]\n",
      " [1.63813388]\n",
      " [1.62914541]\n",
      " [1.62083313]\n",
      " [1.61968492]\n",
      " [1.63887269]\n",
      " [1.63854807]\n",
      " [1.63685022]\n",
      " [1.62731952]\n",
      " [1.6276624 ]\n",
      " [1.63145865]\n",
      " [1.62062604]\n",
      " [1.62983853]\n",
      " [1.62529865]\n",
      " [1.63725654]\n",
      " [1.63649948]\n",
      " [1.63923166]\n",
      " [1.63737996]\n",
      " [1.63856333]\n",
      " [1.63760825]\n",
      " [1.63825834]\n",
      " [1.64036964]\n",
      " [1.62528855]\n",
      " [1.63849702]\n",
      " [1.60860694]\n",
      " [1.63885311]\n",
      " [1.63585414]\n",
      " [1.62704643]\n",
      " [1.63405831]\n",
      " [1.63522187]]\n"
     ]
    }
   ],
   "source": [
    "# 화학요법여부 = 1일때의 위험도\n",
    "print(h_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.61639782]\n",
      " [1.63078801]\n",
      " [1.63458968]\n",
      " [1.63320082]\n",
      " [1.64061032]\n",
      " [1.63954185]\n",
      " [1.63922663]\n",
      " [1.63831836]\n",
      " [1.6390218 ]\n",
      " [1.63738323]\n",
      " [1.63427375]\n",
      " [1.63550085]\n",
      " [1.63390376]\n",
      " [1.63069726]\n",
      " [1.63311347]\n",
      " [1.64013079]\n",
      " [1.63863353]\n",
      " [1.63651303]\n",
      " [1.63848794]\n",
      " [1.63888115]\n",
      " [1.63792942]\n",
      " [1.63339097]\n",
      " [1.61574252]\n",
      " [1.63836956]\n",
      " [1.63826998]\n",
      " [1.6356425 ]\n",
      " [1.6383757 ]\n",
      " [1.63755242]\n",
      " [1.63373441]\n",
      " [1.63073316]\n",
      " [1.63423424]\n",
      " [1.6104286 ]\n",
      " [1.62693384]\n",
      " [1.63913471]\n",
      " [1.63939697]\n",
      " [1.63912767]\n",
      " [1.62699805]\n",
      " [1.63920949]\n",
      " [1.63786636]\n",
      " [1.63069069]\n",
      " [1.63308373]\n",
      " [1.63397955]\n",
      " [1.63620336]\n",
      " [1.62674126]\n",
      " [1.62166519]\n",
      " [1.63936022]\n",
      " [1.62849359]\n",
      " [1.63636169]\n",
      " [1.63229778]\n",
      " [1.61650222]\n",
      " [1.63292727]\n",
      " [1.62387252]\n",
      " [1.63884992]\n",
      " [1.63741577]\n",
      " [1.63320711]\n",
      " [1.63831074]\n",
      " [1.6338075 ]\n",
      " [1.6345863 ]\n",
      " [1.63324617]\n",
      " [1.64007469]\n",
      " [1.63160635]\n",
      " [1.63272807]\n",
      " [1.62274324]\n",
      " [1.62445607]\n",
      " [1.63565169]\n",
      " [1.63497144]\n",
      " [1.63813798]\n",
      " [1.63921794]\n",
      " [1.63522674]\n",
      " [1.6373602 ]\n",
      " [1.63016102]\n",
      " [1.63639347]\n",
      " [1.63896927]\n",
      " [1.62904422]\n",
      " [1.63983633]\n",
      " [1.63786928]\n",
      " [1.63944777]\n",
      " [1.63758925]\n",
      " [1.63036592]\n",
      " [1.63592838]\n",
      " [1.63698586]\n",
      " [1.60745249]\n",
      " [1.63722815]\n",
      " [1.63686441]\n",
      " [1.6395937 ]\n",
      " [1.63785076]\n",
      " [1.63594534]\n",
      " [1.63308321]\n",
      " [1.60445412]\n",
      " [1.63050037]\n",
      " [1.63320183]\n",
      " [1.63979973]\n",
      " [1.63730192]\n",
      " [1.63672901]\n",
      " [1.63765392]\n",
      " [1.63592292]\n",
      " [1.63923383]\n",
      " [1.62790655]\n",
      " [1.63725564]\n",
      " [1.63817807]\n",
      " [1.63528514]\n",
      " [1.63627631]\n",
      " [1.63281488]\n",
      " [1.61277881]\n",
      " [1.60738195]\n",
      " [1.6346363 ]\n",
      " [1.6333956 ]\n",
      " [1.63927328]\n",
      " [1.6398199 ]\n",
      " [1.61640802]\n",
      " [1.63442955]\n",
      " [1.63182226]\n",
      " [1.62929998]\n",
      " [1.63461356]\n",
      " [1.6383829 ]\n",
      " [1.63240849]\n",
      " [1.63830082]\n",
      " [1.63850556]\n",
      " [1.62471411]\n",
      " [1.6318608 ]\n",
      " [1.63794565]\n",
      " [1.63282516]\n",
      " [1.63522478]\n",
      " [1.63729663]\n",
      " [1.63610058]\n",
      " [1.63076317]\n",
      " [1.60098716]\n",
      " [1.63839274]\n",
      " [1.6319037 ]\n",
      " [1.63144213]\n",
      " [1.62056759]\n",
      " [1.63937742]\n",
      " [1.6372241 ]\n",
      " [1.6347707 ]\n",
      " [1.62088987]\n",
      " [1.63848285]\n",
      " [1.63721177]\n",
      " [1.63737705]\n",
      " [1.6360138 ]\n",
      " [1.63924945]\n",
      " [1.63715119]\n",
      " [1.63299701]\n",
      " [1.63345632]\n",
      " [1.63784129]\n",
      " [1.63634604]\n",
      " [1.63914651]\n",
      " [1.63488637]\n",
      " [1.63819779]\n",
      " [1.63868653]\n",
      " [1.63113053]\n",
      " [1.62724759]\n",
      " [1.63821098]\n",
      " [1.64030468]\n",
      " [1.63794799]\n",
      " [1.63662597]\n",
      " [1.63406059]\n",
      " [1.62670921]\n",
      " [1.63578094]\n",
      " [1.63568153]\n",
      " [1.63464269]\n",
      " [1.63963736]\n",
      " [1.63391991]\n",
      " [1.63811563]\n",
      " [1.63235294]\n",
      " [1.63706673]\n",
      " [1.63634515]\n",
      " [1.63862258]\n",
      " [1.63936369]\n",
      " [1.63543309]\n",
      " [1.62592538]\n",
      " [1.63912102]\n",
      " [1.63656374]\n",
      " [1.63786727]\n",
      " [1.62687296]\n",
      " [1.62147737]\n",
      " [1.63903574]\n",
      " [1.63952743]\n",
      " [1.63697391]\n",
      " [1.63539027]\n",
      " [1.63866914]\n",
      " [1.63557522]\n",
      " [1.63449136]\n",
      " [1.63117782]\n",
      " [1.63944443]\n",
      " [1.63461951]\n",
      " [1.62512053]\n",
      " [1.63693075]\n",
      " [1.63922675]\n",
      " [1.63879925]\n",
      " [1.63888007]\n",
      " [1.635704  ]\n",
      " [1.63837224]\n",
      " [1.62062508]\n",
      " [1.63694985]\n",
      " [1.63866316]\n",
      " [1.62887464]\n",
      " [1.63568872]\n",
      " [1.6403151 ]\n",
      " [1.63484785]\n",
      " [1.62841165]\n",
      " [1.63754115]\n",
      " [1.63029992]\n",
      " [1.63268417]\n",
      " [1.63555286]\n",
      " [1.63610602]\n",
      " [1.63529806]\n",
      " [1.63294309]\n",
      " [1.62472735]\n",
      " [1.62414688]\n",
      " [1.63916796]\n",
      " [1.61970547]\n",
      " [1.63985109]\n",
      " [1.63848111]\n",
      " [1.62976919]\n",
      " [1.63834053]\n",
      " [1.63509852]\n",
      " [1.63925815]\n",
      " [1.6364646 ]\n",
      " [1.62926976]\n",
      " [1.61574335]\n",
      " [1.63838987]\n",
      " [1.63759567]\n",
      " [1.6405062 ]\n",
      " [1.63040901]\n",
      " [1.63546154]\n",
      " [1.61624103]\n",
      " [1.63822139]\n",
      " [1.63874262]\n",
      " [1.63821291]\n",
      " [1.63993089]\n",
      " [1.62895412]\n",
      " [1.63958782]\n",
      " [1.64016741]\n",
      " [1.63787147]\n",
      " [1.63792671]\n",
      " [1.63513807]\n",
      " [1.63911664]\n",
      " [1.62361436]\n",
      " [1.61729042]\n",
      " [1.63394859]\n",
      " [1.63556348]\n",
      " [1.6385907 ]\n",
      " [1.63587607]\n",
      " [1.64042879]\n",
      " [1.6354234 ]\n",
      " [1.63993144]\n",
      " [1.63255036]\n",
      " [1.63846626]\n",
      " [1.63269355]\n",
      " [1.62349446]\n",
      " [1.60982195]\n",
      " [1.63312768]\n",
      " [1.63626453]\n",
      " [1.63636163]\n",
      " [1.63701111]\n",
      " [1.63986004]\n",
      " [1.63680983]\n",
      " [1.63373146]\n",
      " [1.63899743]\n",
      " [1.63415013]\n",
      " [1.62523108]\n",
      " [1.63648972]\n",
      " [1.63908464]\n",
      " [1.63704614]\n",
      " [1.63306741]\n",
      " [1.63122478]\n",
      " [1.63843325]\n",
      " [1.63373987]\n",
      " [1.63331345]\n",
      " [1.63971167]\n",
      " [1.63811186]\n",
      " [1.63645996]\n",
      " [1.6269853 ]\n",
      " [1.63769641]\n",
      " [1.6356172 ]\n",
      " [1.63856302]\n",
      " [1.62697139]\n",
      " [1.63958203]\n",
      " [1.63223282]\n",
      " [1.64017955]\n",
      " [1.63771108]\n",
      " [1.624129  ]\n",
      " [1.62751593]\n",
      " [1.62640998]\n",
      " [1.63966779]\n",
      " [1.63833543]\n",
      " [1.63369721]\n",
      " [1.63868973]\n",
      " [1.63632763]\n",
      " [1.63596139]\n",
      " [1.63398995]\n",
      " [1.63751175]\n",
      " [1.63762035]\n",
      " [1.63935013]\n",
      " [1.6358299 ]\n",
      " [1.64058102]\n",
      " [1.63905211]\n",
      " [1.63664328]\n",
      " [1.63856153]\n",
      " [1.63395065]\n",
      " [1.63319382]\n",
      " [1.63758666]\n",
      " [1.63878067]\n",
      " [1.63548462]\n",
      " [1.63649661]\n",
      " [1.64068408]\n",
      " [1.63160222]\n",
      " [1.64080745]\n",
      " [1.63999018]\n",
      " [1.62539113]\n",
      " [1.63731722]\n",
      " [1.64029768]\n",
      " [1.6237529 ]\n",
      " [1.63950248]\n",
      " [1.63905227]\n",
      " [1.63905279]\n",
      " [1.63528535]\n",
      " [1.62946245]\n",
      " [1.63890734]\n",
      " [1.63258251]\n",
      " [1.63858234]\n",
      " [1.63208472]\n",
      " [1.63922993]\n",
      " [1.63977778]\n",
      " [1.63050785]\n",
      " [1.6366718 ]\n",
      " [1.63489815]\n",
      " [1.63945593]\n",
      " [1.63529102]\n",
      " [1.63699922]\n",
      " [1.63600975]\n",
      " [1.62718677]\n",
      " [1.63699769]\n",
      " [1.63949884]\n",
      " [1.63644797]\n",
      " [1.60691602]\n",
      " [1.63789394]\n",
      " [1.63238097]\n",
      " [1.62100952]\n",
      " [1.63795336]\n",
      " [1.63542131]\n",
      " [1.6376547 ]\n",
      " [1.6388258 ]\n",
      " [1.63709264]\n",
      " [1.63928503]\n",
      " [1.63381844]\n",
      " [1.63821845]\n",
      " [1.61523426]\n",
      " [1.63591142]\n",
      " [1.63468118]\n",
      " [1.6391534 ]\n",
      " [1.64044416]\n",
      " [1.63834122]\n",
      " [1.62923628]\n",
      " [1.62088008]\n",
      " [1.61968554]\n",
      " [1.63906727]\n",
      " [1.63867154]\n",
      " [1.63701974]\n",
      " [1.62725857]\n",
      " [1.62769469]\n",
      " [1.63154605]\n",
      " [1.62055749]\n",
      " [1.62993661]\n",
      " [1.625256  ]\n",
      " [1.63737095]\n",
      " [1.63659268]\n",
      " [1.63942141]\n",
      " [1.63756138]\n",
      " [1.63872239]\n",
      " [1.63777972]\n",
      " [1.63841443]\n",
      " [1.64042942]\n",
      " [1.62528521]\n",
      " [1.63861839]\n",
      " [1.60869445]\n",
      " [1.63895591]\n",
      " [1.6359741 ]\n",
      " [1.62721225]\n",
      " [1.63422798]\n",
      " [1.63526454]]\n"
     ]
    }
   ],
   "source": [
    "# 화학요법여부 = 0일때의 위험도\n",
    "print(h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.41217195]\n",
      " [1.18666832]\n",
      " [1.27857363]\n",
      " [1.37257092]\n",
      " [1.11697971]\n",
      " [1.19803505]\n",
      " [1.59103813]\n",
      " [1.30679512]\n",
      " [1.28415119]\n",
      " [1.47349863]\n",
      " [1.50344406]\n",
      " [1.16074436]\n",
      " [1.17571733]\n",
      " [1.16884347]\n",
      " [1.20010814]\n",
      " [1.36462898]\n",
      " [1.24496517]\n",
      " [1.6009692 ]\n",
      " [1.26194617]\n",
      " [1.24521196]\n",
      " [1.15015364]\n",
      " [1.3131271 ]\n",
      " [1.28691009]\n",
      " [1.26132443]\n",
      " [1.77795314]\n",
      " [1.5316812 ]\n",
      " [1.30734129]\n",
      " [1.26482331]\n",
      " [1.31772171]\n",
      " [1.05512287]\n",
      " [1.2504182 ]\n",
      " [1.34434334]\n",
      " [1.24405584]\n",
      " [1.50998403]\n",
      " [1.23656061]\n",
      " [1.34645006]\n",
      " [1.07687727]\n",
      " [1.31289628]\n",
      " [1.25158998]\n",
      " [1.15025103]\n",
      " [1.03086123]\n",
      " [1.51462387]\n",
      " [1.31131915]\n",
      " [1.07557972]\n",
      " [1.41247087]\n",
      " [1.23070448]\n",
      " [1.17029674]\n",
      " [1.54258637]\n",
      " [1.03907487]\n",
      " [1.07462057]\n",
      " [1.18727901]\n",
      " [1.23112548]\n",
      " [1.21373158]\n",
      " [1.39965499]\n",
      " [1.06534903]\n",
      " [1.34371804]\n",
      " [1.16376857]\n",
      " [1.09624248]\n",
      " [1.1729761 ]\n",
      " [1.26004395]\n",
      " [1.15773627]\n",
      " [1.03075485]\n",
      " [1.32972134]\n",
      " [1.10360251]\n",
      " [1.59757836]\n",
      " [1.14594088]\n",
      " [1.5313234 ]\n",
      " [1.61299323]\n",
      " [1.08911066]\n",
      " [1.29986113]\n",
      " [1.15212458]\n",
      " [1.17106841]\n",
      " [1.26309049]\n",
      " [1.10108946]\n",
      " [1.13916193]\n",
      " [1.36732739]\n",
      " [1.24724099]\n",
      " [1.26833153]\n",
      " [1.21322762]\n",
      " [1.38234917]\n",
      " [1.30089399]\n",
      " [1.36701727]\n",
      " [1.41453227]\n",
      " [1.57437053]\n",
      " [1.5794034 ]\n",
      " [1.21632246]\n",
      " [1.60008457]\n",
      " [1.26197188]\n",
      " [1.33440176]\n",
      " [1.46351842]\n",
      " [1.15859005]\n",
      " [1.16396605]\n",
      " [1.17367751]\n",
      " [1.41434551]\n",
      " [1.44482751]\n",
      " [1.13642597]\n",
      " [1.53839272]\n",
      " [1.13483749]\n",
      " [1.32730141]\n",
      " [1.32669678]\n",
      " [1.30738689]\n",
      " [1.22574984]\n",
      " [1.60210905]\n",
      " [1.13337389]\n",
      " [1.20482851]\n",
      " [1.15283559]\n",
      " [1.30432812]\n",
      " [1.25981311]\n",
      " [1.13834327]\n",
      " [1.06913451]\n",
      " [1.36205471]\n",
      " [1.11712593]\n",
      " [1.18846125]\n",
      " [1.32071122]\n",
      " [1.25944581]\n",
      " [1.15381192]\n",
      " [1.28091363]\n",
      " [1.74555187]\n",
      " [1.05596515]\n",
      " [1.37910687]\n",
      " [1.33608218]\n",
      " [1.28908879]\n",
      " [1.69811839]\n",
      " [1.3573918 ]\n",
      " [1.11123174]\n",
      " [1.18234405]\n",
      " [1.32316036]\n",
      " [1.31597902]\n",
      " [1.15402224]\n",
      " [1.13699778]\n",
      " [1.19939516]\n",
      " [1.20582906]\n",
      " [1.52344844]\n",
      " [1.12325   ]\n",
      " [1.22068631]\n",
      " [1.42130433]\n",
      " [1.17341185]\n",
      " [1.51968452]\n",
      " [1.04781655]\n",
      " [1.23673168]\n",
      " [1.25980527]\n",
      " [1.24217505]\n",
      " [1.31727743]\n",
      " [1.26549233]\n",
      " [1.11895102]\n",
      " [1.17652525]\n",
      " [1.60730015]\n",
      " [1.21607577]\n",
      " [1.34617795]\n",
      " [1.17015531]\n",
      " [1.08073408]\n",
      " [1.71316433]\n",
      " [1.17134648]\n",
      " [1.23791929]\n",
      " [1.23818454]\n",
      " [1.4141036 ]\n",
      " [1.13720489]\n",
      " [1.28907162]\n",
      " [1.24713865]\n",
      " [1.51892005]\n",
      " [1.18575066]\n",
      " [1.30046822]\n",
      " [1.30668681]\n",
      " [1.36097798]\n",
      " [1.22348694]\n",
      " [1.36501311]\n",
      " [1.22600755]\n",
      " [1.32202664]\n",
      " [1.13726841]\n",
      " [1.29069889]\n",
      " [1.36077212]\n",
      " [1.33596828]\n",
      " [1.18235446]\n",
      " [1.09883868]\n",
      " [1.21894173]\n",
      " [1.36068893]\n",
      " [1.17223288]\n",
      " [1.48104953]\n",
      " [1.28011041]\n",
      " [1.23415084]\n",
      " [1.65401015]\n",
      " [1.12954444]\n",
      " [1.06175377]\n",
      " [1.21205916]\n",
      " [1.16477452]\n",
      " [1.52285763]\n",
      " [1.20726651]\n",
      " [1.51607319]\n",
      " [1.21471563]\n",
      " [1.32412751]\n",
      " [1.17921892]\n",
      " [1.31299351]\n",
      " [1.30211799]\n",
      " [1.30154951]\n",
      " [1.67379398]\n",
      " [1.43125834]\n",
      " [1.62807366]\n",
      " [1.15443673]\n",
      " [1.33288573]\n",
      " [1.07204184]\n",
      " [1.20234054]\n",
      " [1.16699126]\n",
      " [1.25685246]\n",
      " [1.33785547]\n",
      " [1.25005083]\n",
      " [1.14785034]\n",
      " [1.03853711]\n",
      " [1.52584738]\n",
      " [1.4176128 ]\n",
      " [1.26104252]\n",
      " [1.11345268]\n",
      " [1.21827026]\n",
      " [1.28755836]\n",
      " [1.03349619]\n",
      " [1.27647015]\n",
      " [1.3337936 ]\n",
      " [1.34109888]\n",
      " [1.64084614]\n",
      " [1.22916783]\n",
      " [1.56837522]\n",
      " [1.30532847]\n",
      " [1.30512407]\n",
      " [1.17114832]\n",
      " [1.13090274]\n",
      " [1.22951113]\n",
      " [1.51011276]\n",
      " [1.33921019]\n",
      " [1.59149344]\n",
      " [1.30008819]\n",
      " [1.15634433]\n",
      " [1.15813201]\n",
      " [1.18022888]\n",
      " [1.15996853]\n",
      " [1.2387083 ]\n",
      " [1.37518621]\n",
      " [1.06512421]\n",
      " [1.17134051]\n",
      " [1.10936038]\n",
      " [1.41630301]\n",
      " [1.21449691]\n",
      " [1.31645568]\n",
      " [1.36083302]\n",
      " [1.48209291]\n",
      " [1.20125736]\n",
      " [1.28094472]\n",
      " [1.28230467]\n",
      " [1.14064508]\n",
      " [1.27719933]\n",
      " [1.2745524 ]\n",
      " [1.03411466]\n",
      " [1.18840567]\n",
      " [1.22784015]\n",
      " [1.56747764]\n",
      " [1.70154848]\n",
      " [1.6534225 ]\n",
      " [1.34160168]\n",
      " [1.22271274]\n",
      " [1.1252914 ]\n",
      " [1.36555875]\n",
      " [1.06453562]\n",
      " [1.33137342]\n",
      " [1.35422284]\n",
      " [1.25647973]\n",
      " [1.30430415]\n",
      " [1.13397965]\n",
      " [1.05453821]\n",
      " [1.22546932]\n",
      " [1.44058418]\n",
      " [1.17610773]\n",
      " [1.31583023]\n",
      " [1.25197175]\n",
      " [1.31480731]\n",
      " [1.14355924]\n",
      " [1.41295849]\n",
      " [1.27980105]\n",
      " [1.53636837]\n",
      " [1.15149617]\n",
      " [1.26548932]\n",
      " [1.03940742]\n",
      " [1.20910974]\n",
      " [1.21623389]\n",
      " [1.12387738]\n",
      " [1.23711858]\n",
      " [1.11323576]\n",
      " [1.21584545]\n",
      " [1.33802429]\n",
      " [1.14737743]\n",
      " [1.29963077]\n",
      " [1.25953086]\n",
      " [1.65123144]\n",
      " [1.21842157]\n",
      " [1.33080601]\n",
      " [1.30769093]\n",
      " [1.25850216]\n",
      " [1.2164461 ]\n",
      " [1.15807363]\n",
      " [1.24888756]\n",
      " [1.21523253]\n",
      " [1.18190036]\n",
      " [1.1791923 ]\n",
      " [1.19478604]\n",
      " [1.7014605 ]\n",
      " [1.60644077]\n",
      " [1.22708916]\n",
      " [1.13114003]\n",
      " [1.17007816]\n",
      " [1.04387563]\n",
      " [1.15629936]\n",
      " [1.34190836]\n",
      " [1.13112488]\n",
      " [1.30296349]\n",
      " [1.14104132]\n",
      " [1.67192013]\n",
      " [1.301037  ]\n",
      " [1.3245875 ]\n",
      " [1.33432827]\n",
      " [1.27809578]\n",
      " [1.12140684]\n",
      " [1.23481008]\n",
      " [1.07398778]\n",
      " [1.29369421]\n",
      " [1.21529355]\n",
      " [1.3759783 ]\n",
      " [1.25454312]\n",
      " [1.48520771]\n",
      " [1.56375403]\n",
      " [1.27308156]\n",
      " [1.27695538]\n",
      " [1.07135788]\n",
      " [1.44168824]\n",
      " [1.28672693]\n",
      " [1.24261777]\n",
      " [1.41012953]\n",
      " [1.21480649]\n",
      " [1.14918617]\n",
      " [1.07907307]\n",
      " [1.4582899 ]\n",
      " [1.28435421]\n",
      " [1.08024786]\n",
      " [1.57698755]\n",
      " [1.34568717]\n",
      " [1.39123052]\n",
      " [1.47605738]\n",
      " [1.33104323]\n",
      " [1.17842275]\n",
      " [1.18795403]\n",
      " [1.33833981]\n",
      " [1.58358413]\n",
      " [1.35648983]\n",
      " [1.03121844]\n",
      " [1.69051244]\n",
      " [1.31820608]\n",
      " [1.52206534]\n",
      " [1.15028932]\n",
      " [1.21459443]\n",
      " [1.15154559]\n",
      " [1.23678769]\n",
      " [1.18281559]\n",
      " [1.25651248]\n",
      " [1.0814158 ]\n",
      " [1.21336401]\n",
      " [1.52111731]\n",
      " [1.12525591]\n",
      " [1.24947562]\n",
      " [1.13224398]\n",
      " [1.21269666]\n",
      " [1.17048905]\n",
      " [1.26767503]\n",
      " [1.34350532]\n",
      " [1.08296147]\n",
      " [1.29112521]\n",
      " [1.26027022]\n",
      " [1.16173523]\n",
      " [1.19330539]\n",
      " [1.31196906]\n",
      " [1.42822776]\n",
      " [1.24858616]\n",
      " [1.54390234]\n",
      " [1.39160011]\n",
      " [1.28935537]\n",
      " [1.15312661]]\n"
     ]
    }
   ],
   "source": [
    "#CHF=1 - CHF=0\n",
    "print(np.exp(rec_trt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  0.9998906542175069\n",
      "SE :  [4.38459156e-06]\n",
      "95% CI :  (array([0.99988203]), array([0.99989928]))\n"
     ]
    }
   ],
   "source": [
    "#WHAS 화학요법여부의 ACE\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  1.3697059381297867\n",
      "SE :  [0.00916941]\n",
      "95% CI :  (array([1.3516768]), array([1.38773508]))\n"
     ]
    }
   ],
   "source": [
    "x_trt = numpy.copy(test_dataset['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,6] = 1 \n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,6] = 0\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(test_dataset['x'], 1, 0, 6)\n",
    "\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tunning\n",
    "datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/support_train_test.h5')\n",
    "train_data = datasets['train']\n",
    "\n",
    "def get_optimizer_from_str(update_fn):\n",
    "    if update_fn == 'sgd':\n",
    "        return lasagne.updates.sgd\n",
    "    elif update_fn == 'adam':\n",
    "        return lasagne.updates.adam\n",
    "    elif update_fn == 'rmsprop':\n",
    "        return lasagne.updates.rmsprop\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_objective_function(num_epochs):\n",
    "\n",
    "    def format_to_deepsurv(x, y):\n",
    "        return {\n",
    "            'x': x,\n",
    "            'e': y[:,0].astype(np.int32),\n",
    "            't': y[:,1].astype(np.float32)\n",
    "        }\n",
    "\n",
    "    def get_hyperparams(params):\n",
    "        hyperparams = {\n",
    "            'batch_norm': False,\n",
    "            'activation': 'selu',\n",
    "            'standardize': True\n",
    "        }\n",
    "        # @TODO add default parameters and only take necessary args from params\n",
    "        # protect from params including some other key\n",
    "\n",
    "        if 'num_layers' in params and 'num_nodes' in params:\n",
    "            params['hidden_layers_sizes'] = [int(params['num_nodes'])] * int(params['num_layers'])\n",
    "            del params['num_layers']\n",
    "            del params['num_nodes']\n",
    "\n",
    "\n",
    "        hyperparams.update(params)\n",
    "        return hyperparams\n",
    "\n",
    "    def train_deepsurv(x_train, y_train, x_test, y_test,\n",
    "        **kwargs):\n",
    "        # Standardize the datasets\n",
    "        train_mean = x_train.mean(axis = 0)\n",
    "        train_std = x_train.std(axis = 0)\n",
    "\n",
    "        x_train = (x_train - train_mean) / train_std\n",
    "        x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "        train_data = format_to_deepsurv(x_train, y_train)\n",
    "        valid_data = format_to_deepsurv(x_test, y_test)\n",
    "\n",
    "        hyperparams = get_hyperparams(kwargs)\n",
    "\n",
    "        network = DeepSurv(n_in=x_train.shape[1], **hyperparams)\n",
    "        metrics = network.train(train_data, n_epochs = num_epochs,\n",
    "            update_fn = lasagne.updates.nesterov_momentum, verbose = False)\n",
    "\n",
    "        result = network.get_concordance_index(**valid_data)\n",
    "        return result\n",
    "\n",
    "    return train_deepsurv\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    NUM_EPOCHS = 1000\n",
    "    NUM_FOLDS = 5\n",
    "\n",
    "    x = train_data['x']\n",
    "    e = train_data['e']\n",
    "    \n",
    "    t = train_data['t']\n",
    "    y = np.column_stack((e, t))\n",
    "    \n",
    "    \n",
    "\n",
    "    opt_fxn = get_objective_function(NUM_EPOCHS)\n",
    "    opt_fxn = optunity.cross_validated(x=x, y=y, num_folds=NUM_FOLDS,\n",
    "        strata=False)(opt_fxn)\n",
    "\n",
    "    opt_params, _, _ = optunity.maximize(opt_fxn, num_evals=20,\n",
    "        learning_rate =[0.01,0.05],\n",
    "        lr_decay = [0.0001, 0.001], \n",
    "        momentum = [0.8, 0.95],\n",
    "        L2_reg = [2.0, 7.0], \n",
    "        dropout = [0.3, 0.6],\n",
    "        num_layers = [1,3],\n",
    "        num_nodes = [20,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 2.771484375,\n",
       " 'dropout': 0.29277343750000007,\n",
       " 'learning_rate': 0.013203125,\n",
       " 'lr_decay': 0.0007626953125,\n",
       " 'momentum': 0.90107421875,\n",
       " 'num_layers': 1.72265625,\n",
       " 'num_nodes': 34.697265625}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#첫번쨰\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 3.11083984375,\n",
       " 'dropout': 0.6570800781249999,\n",
       " 'learning_rate': 0.01033203125,\n",
       " 'lr_decay': 0.000137353515625,\n",
       " 'momentum': 0.9317626953125,\n",
       " 'num_layers': 1.7041015625,\n",
       " 'num_nodes': 41.96044921875}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#두번째\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 6.716796875,\n",
       " 'dropout': 0.41230468750000004,\n",
       " 'learning_rate': 0.029140625000000003,\n",
       " 'lr_decay': 0.0002775390625,\n",
       " 'momentum': 0.81318359375,\n",
       " 'num_layers': 1.33203125,\n",
       " 'num_nodes': 23.955078125}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#세번째\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 2.2001953125,\n",
       " 'dropout': 0.54931640625,\n",
       " 'learning_rate': 0.049570312500000005,\n",
       " 'lr_decay': 0.00047880859374999996,\n",
       " 'momentum': 0.944873046875,\n",
       " 'num_layers': 1.732421875,\n",
       " 'num_nodes': 40.7275390625}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#네번쨰\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.6491997159551604}\n",
      "Test metrics: {'c_index': 0.6171343531205548, 'c_index_bootstrap': {'mean': 0.6162325018085759, 'confidence_interval': (0.6145522038350946, 0.6179127997820573)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\"learning_rate\": 0.013203125, \n",
    "               \"dropout\": 0.29277343750000007, \n",
    "               \"lr_decay\": 0.0007626953125, \n",
    "               \"momentum\": 0.90107421875, \n",
    "               \"L2_reg\": 2.771484375, \n",
    "               \"batch_norm\": False, \n",
    "               \"standardize\": True, \n",
    "               \"n_in\": 14, \n",
    "               \"hidden_layers_sizes\": [35,35], \n",
    "               \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/support_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 150,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.6693106005739599}\n",
      "Test metrics: {'c_index': 0.6137037437309958, 'c_index_bootstrap': {'mean': 0.6139358744228821, 'confidence_interval': (0.6123454786014307, 0.6155262702443335)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\"learning_rate\": 0.049570312500000005, \n",
    "               \"dropout\": 0.54931640625, \n",
    "               \"lr_decay\": 0.00047880859374999996, \n",
    "               \"momentum\": 0.944873046875, \n",
    "               \"L2_reg\": 2.2001953125, \n",
    "               \"batch_norm\": False, \n",
    "               \"standardize\": True, \n",
    "               \"n_in\": 14, \n",
    "               \"hidden_layers_sizes\": [41,41], \n",
    "               \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    datasets = utils.load_datasets('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/support_train_test.h5')\n",
    "    norm_vals = {\n",
    "            'mean' : datasets['train']['x'].mean(axis =0),\n",
    "            'std'  : datasets['train']['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "    else:\n",
    "        valid_data = None\n",
    "        metrics = model.train(datasets['train'], valid_data, n_epochs = 200,\n",
    "        update_fn = utils.get_optimizer_from_str('adam'),\n",
    "        validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    train_data = datasets['train']\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if 'valid' in datasets:\n",
    "        valid_data = datasets['valid']\n",
    "        if hyperparams['standardize']:\n",
    "            valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "            metrics = evaluate_model(model, valid_data)\n",
    "        print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    if 'test' in datasets:\n",
    "        test_dataset = utils.standardize_dataset(datasets['test'], norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "        print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min :  0.9161711977758715\n",
      "1분위수 :  0.999999982144606\n",
      "중앙값 :  1.000000020480738\n",
      "3분위수 :  1.000047664847534\n",
      "max :  1.092235578539729\n",
      "평균 :  1.0002056175405536\n",
      "표준편차 :  1.0053136017813795\n"
     ]
    }
   ],
   "source": [
    "#각 개별 환자의 trt별 효과 차이\n",
    "rec_trt = model.recommend_treatment(datasets['test']['x'], 1, 0, 4)\n",
    "print('min : ',np.exp(np.min(rec_trt)))\n",
    "print('1분위수 : ',np.exp(np.percentile(rec_trt, 25)))\n",
    "print('중앙값 : ',np.exp(np.median(rec_trt)))\n",
    "print('3분위수 : ',np.exp(np.percentile(rec_trt, 75)))\n",
    "print('max : ',np.exp(np.max(rec_trt)))\n",
    "print('평균 : ',np.exp(np.mean(rec_trt)))\n",
    "print('표준편차 : ',np.exp(np.std(rec_trt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trt = numpy.copy(datasets['test']['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,4] = 1 #화학요법 받음\n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,4] = 0 #화학요법 안받음\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(datasets['test']['x'], 1, 0, 4)\n",
    "\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  1.0002056175405536\n",
      "SE :  [0.00012582]\n",
      "95% CI :  (array([0.99995884]), array([1.00045239]))\n"
     ]
    }
   ],
   "source": [
    "#WHAS 화학요법여부의 ACE\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  1.247117628572232\n",
      "SE :  [0.00785505]\n",
      "95% CI :  (array([1.2317115]), array([1.26252376]))\n"
     ]
    }
   ],
   "source": [
    "x_trt = numpy.copy(test_dataset['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,6] = 1 \n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,6] = 0\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(test_dataset['x'], 1, 0, 6)\n",
    "\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NWTCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nwtco 데이터 불러오기\n",
    "nwtco = pd.read_csv('C:/Users/ASUS/Dropbox/석사학위논문/DeepSurv-master/data/nwtco.csv')\n",
    "train_df = nwtco.drop('seqno', axis = 1)\n",
    "train_df = train_df.rename(columns = {'rel':'Event', 'edrel':'Time'})\n",
    "\n",
    "\n",
    "#data split\n",
    "train_df, test_df = train_test_split(train_df, test_size = 0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.2)\n",
    "\n",
    "# event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "# time_col is the header in the df that represents the event time\n",
    "def dataframe_to_deepsurv_ds(df, event_col = 'Event', time_col = 'Time'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "# If the headers of the csv change, you can replace the values of \n",
    "# 'event_col' and 'time_col' with the names of the new headers\n",
    "# You can also use this function on your training dataset, validation dataset, and testing dataset\n",
    "train_data = dataframe_to_deepsurv_ds(train_df, event_col = 'Event', time_col= 'Time')\n",
    "val_data = dataframe_to_deepsurv_ds(val_df, event_col = 'Event', time_col = 'Time')\n",
    "test_data = dataframe_to_deepsurv_ds(test_df, event_col = 'Event', time_col = 'Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': [0.001, 0.01], 'lr_decay': [0.0001, 0.001], 'momentum': [0.8, 0.95], 'L2_reg': [2.0, 7.0], 'dropout': [0.1, 0.4], 'num_layers': [1, 3], 'num_nodes': [20, 45], 'num_particles': 10, 'num_generations': 2, 'solver_name': 'particle swarm'}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tunning\n",
    "def get_optimizer_from_str(update_fn):\n",
    "    if update_fn == 'sgd':\n",
    "        return lasagne.updates.sgd\n",
    "    elif update_fn == 'adam':\n",
    "        return lasagne.updates.adam\n",
    "    elif update_fn == 'rmsprop':\n",
    "        return lasagne.updates.rmsprop\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_objective_function(num_epochs):\n",
    "\n",
    "    def format_to_deepsurv(x, y):\n",
    "        return {\n",
    "            'x': x,\n",
    "            'e': y[:,0].astype(np.int32),\n",
    "            't': y[:,1].astype(np.float32)\n",
    "        }\n",
    "\n",
    "    def get_hyperparams(params):\n",
    "        hyperparams = {\n",
    "            'batch_norm': False,\n",
    "            'activation': 'selu',\n",
    "            'standardize': True\n",
    "        }\n",
    "        # @TODO add default parameters and only take necessary args from params\n",
    "        # protect from params including some other key\n",
    "\n",
    "        if 'num_layers' in params and 'num_nodes' in params:\n",
    "            params['hidden_layers_sizes'] = [int(params['num_nodes'])] * int(params['num_layers'])\n",
    "            del params['num_layers']\n",
    "            del params['num_nodes']\n",
    "\n",
    "\n",
    "        hyperparams.update(params)\n",
    "        return hyperparams\n",
    "\n",
    "    def train_deepsurv(x_train, y_train, x_test, y_test,\n",
    "        **kwargs):\n",
    "        # Standardize the datasets\n",
    "        train_mean = x_train.mean(axis = 0)\n",
    "        train_std = x_train.std(axis = 0)\n",
    "\n",
    "        x_train = (x_train - train_mean) / train_std\n",
    "        x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "        train_data = format_to_deepsurv(x_train, y_train)\n",
    "        valid_data = format_to_deepsurv(x_test, y_test)\n",
    "\n",
    "        hyperparams = get_hyperparams(kwargs)\n",
    "\n",
    "        network = deep_surv.DeepSurv(n_in=x_train.shape[1], **hyperparams)\n",
    "        metrics = network.train(train_data, n_epochs = num_epochs,\n",
    "            update_fn = lasagne.updates.nesterov_momentum, verbose = False)\n",
    "\n",
    "        result = network.get_concordance_index(**valid_data)\n",
    "        return result\n",
    "\n",
    "    return train_deepsurv\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    NUM_EPOCHS = 120\n",
    "    NUM_FOLDS = 5\n",
    "\n",
    "    x = train_data['x']\n",
    "    e = train_data['e']\n",
    "    \n",
    "    t = train_data['t']\n",
    "    y = np.column_stack((e, t))\n",
    "    \n",
    "    \n",
    "\n",
    "    opt_fxn = get_objective_function(NUM_EPOCHS)\n",
    "    opt_fxn = optunity.cross_validated(x=x, y=y, num_folds=NUM_FOLDS,\n",
    "        strata=False)(opt_fxn)\n",
    "\n",
    "    opt_params, _, _ = optunity.maximize(opt_fxn, num_evals=20,\n",
    "        learning_rate =[0.001,0.01], \n",
    "        lr_decay = [0.0001, 0.001], \n",
    "        momentum = [0.8, 0.95],\n",
    "        L2_reg = [2.0, 7.0], \n",
    "        dropout = [0.1, 0.4],\n",
    "        num_layers = [1,3],\n",
    "        num_nodes = [20,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 3.3701171875,\n",
       " 'dropout': 0.1640897839444557,\n",
       " 'learning_rate': 0.006021831766585077,\n",
       " 'lr_decay': 0.00046158203124999997,\n",
       " 'momentum': 0.9012267633106269,\n",
       " 'num_layers': 2.4120937788122525,\n",
       " 'num_nodes': 22.008902202887633}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\theano\\gpuarray\\dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.7174880375851357}\n",
      "Test metrics: {'c_index': 0.7415518863889127, 'c_index_bootstrap': {'mean': 0.7390783960491367, 'confidence_interval': (0.7343040408602651, 0.7438527512380083)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0005151337890625001, \n",
    "              \"dropout\": 0.059189453125, \n",
    "              \"lr_decay\": 0.00062470703125, \n",
    "              \"momentum\": 0.812744140625, \n",
    "              \"L2_reg\": 3.7138671875,\n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 6, \n",
    "              \"hidden_layers_sizes\": [26,26], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    norm_vals = {\n",
    "            'mean' : train_data['x'].mean(axis =0),\n",
    "            'std'  : train_data['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    \n",
    "    valid_data = None\n",
    "    metrics = model.train(train_data, valid_data, n_epochs = 1200,\n",
    "    update_fn = utils.get_optimizer_from_str('adam'),\n",
    "    validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "\n",
    "    test_dataset = utils.standardize_dataset(test_data, norm_vals['mean'], norm_vals['std'])\n",
    "    metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.7177757451025231}\n",
      "Test metrics: {'c_index': 0.7234871768044675, 'c_index_bootstrap': {'mean': 0.7227165492101829, 'confidence_interval': (0.7171184008972894, 0.7283146975230764)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0005151337890625001, \n",
    "              \"dropout\": 0.059189453125, \n",
    "              \"lr_decay\": 0.00062470703125, \n",
    "              \"momentum\": 0.812744140625, \n",
    "              \"L2_reg\": 3.7138671875,\n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 6, \n",
    "              \"hidden_layers_sizes\": [26,26], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    norm_vals = {\n",
    "            'mean' : train_data['x'].mean(axis =0),\n",
    "            'std'  : train_data['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    \n",
    "    valid_data = None\n",
    "    metrics = model.train(train_data, valid_data, n_epochs = 1200,\n",
    "    update_fn = utils.get_optimizer_from_str('adam'),\n",
    "    validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "\n",
    "    test_dataset = utils.standardize_dataset(test_data, norm_vals['mean'], norm_vals['std'])\n",
    "    metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.734662319763123}\n",
      "Test metrics: {'c_index': 0.6621194234328771, 'c_index_bootstrap': {'mean': 0.662619587478369, 'confidence_interval': (0.6569200485354942, 0.6683191264212438)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.0005151337890625001, \n",
    "              \"dropout\": 0.059189453125, \n",
    "              \"lr_decay\": 0.00062470703125, \n",
    "              \"momentum\": 0.812744140625, \n",
    "              \"L2_reg\": 3.7138671875,\n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 6, \n",
    "              \"hidden_layers_sizes\": [26,26], \n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    norm_vals = {\n",
    "            'mean' : train_data['x'].mean(axis =0),\n",
    "            'std'  : train_data['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "    \n",
    "    valid_data = None\n",
    "    metrics = model.train(train_data, valid_data, n_epochs = 1200,\n",
    "    update_fn = utils.get_optimizer_from_str('adam'),\n",
    "    validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "\n",
    "    test_dataset = utils.standardize_dataset(test_data, norm_vals['mean'], norm_vals['std'])\n",
    "    metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACE :  1.3208000279490315\n",
      "SE :  [0.00746401]\n",
      "95% CI :  (array([1.3061488]), array([1.33545126]))\n"
     ]
    }
   ],
   "source": [
    "x_trt = numpy.copy(test_dataset['x'])\n",
    "\n",
    "true = model.predict_risk(x_trt)\n",
    "x_trt[:,1] = 1 \n",
    "h_1 = model.predict_risk(x_trt)\n",
    "x_trt[:,1] = 0\n",
    "h_0 = model.predict_risk(x_trt)\n",
    "rec_trt = model.recommend_treatment(test_dataset['x'], 1, 0, 1)\n",
    "\n",
    "x = rec_trt\n",
    "mean = np.exp(np.mean(x))\n",
    "SE = stats.sem(x)\n",
    "print('ACE : ',mean)\n",
    "print('SE : ',  SE)\n",
    "print('95% CI : ', stats.t.interval(0.95, len(x)-1, loc=mean, scale=SE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams ={\"learning_rate\": 0.006021831766585077, \n",
    "              \"dropout\": 0.1640897839444557, \n",
    "              \"lr_decay\": 0.00046158203124999997, \n",
    "              \"momentum\": 0.9012267633106269, \n",
    "              \"L2_reg\": 3.3701171875,\n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": True, \n",
    "              \"n_in\": 6, \n",
    "              \"hidden_layers_sizes\": [22,22], \n",
    "              \"activation\": \"selu\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "def generate_data(treatment_group = False):\n",
    "    np.random.seed(123)\n",
    "    sd = deepsurv.datasets.SimulatedData(5, num_features = 15,\n",
    "        treatment_group = treatment_group)\n",
    "    train_data = sd.generate_data(2000,method = 'gaussian')\n",
    "    valid_data = sd.generate_data(600,method = 'gaussian')\n",
    "    test_data = sd.generate_data(600,method = 'gaussian')\n",
    "\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "train_data, valid_data, test_data = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper-parameter tuning\n",
    "def get_optimizer_from_str(update_fn):\n",
    "    if update_fn == 'sgd':\n",
    "        return lasagne.updates.sgd\n",
    "    elif update_fn == 'adam':\n",
    "        return lasagne.updates.adam\n",
    "    elif update_fn == 'rmsprop':\n",
    "        return lasagne.updates.rmsprop\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_objective_function(num_epochs):\n",
    "\n",
    "    def format_to_deepsurv(x, y):\n",
    "        return {\n",
    "            'x': x,\n",
    "            'e': y[:,0].astype(np.int32),\n",
    "            't': y[:,1].astype(np.float32)\n",
    "        }\n",
    "\n",
    "    def get_hyperparams(params):\n",
    "        hyperparams = {\n",
    "            'batch_norm': False,\n",
    "            'activation': 'selu',\n",
    "            'standardize': True\n",
    "        }\n",
    "        # @TODO add default parameters and only take necessary args from params\n",
    "        # protect from params including some other key\n",
    "\n",
    "        if 'num_layers' in params and 'num_nodes' in params:\n",
    "            params['hidden_layers_sizes'] = [int(params['num_nodes'])] * int(params['num_layers'])\n",
    "            del params['num_layers']\n",
    "            del params['num_nodes']\n",
    "\n",
    "\n",
    "        hyperparams.update(params)\n",
    "        return hyperparams\n",
    "\n",
    "    def train_deepsurv(x_train, y_train, x_test, y_test,\n",
    "        **kwargs):\n",
    "        # Standardize the datasets\n",
    "        train_mean = x_train.mean(axis = 0)\n",
    "        train_std = x_train.std(axis = 0)\n",
    "\n",
    "        x_train = (x_train - train_mean) / train_std\n",
    "        x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "        train_data = format_to_deepsurv(x_train, y_train)\n",
    "        valid_data = format_to_deepsurv(x_test, y_test)\n",
    "\n",
    "        hyperparams = get_hyperparams(kwargs)\n",
    "\n",
    "        network = DeepSurv(n_in=x_train.shape[1], **hyperparams)\n",
    "        metrics = network.train(train_data, n_epochs = num_epochs,\n",
    "            update_fn = lasagne.updates.nesterov_momentum, verbose = False)\n",
    "\n",
    "        result = network.get_concordance_index(**valid_data)\n",
    "        return result\n",
    "\n",
    "    return train_deepsurv\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    NUM_EPOCHS = 1200\n",
    "    NUM_FOLDS = 5\n",
    "\n",
    "    x = train_data['x']\n",
    "    e = train_data['e']\n",
    "    \n",
    "    t = train_data['t']\n",
    "    y = np.column_stack((e, t))\n",
    "    \n",
    "    \n",
    "\n",
    "    opt_fxn = get_objective_function(NUM_EPOCHS)\n",
    "    opt_fxn = optunity.cross_validated(x=x, y=y, num_folds=NUM_FOLDS,\n",
    "        strata=False)(opt_fxn)\n",
    "\n",
    "    opt_params, _, _ = optunity.maximize(opt_fxn, num_evals=10,\n",
    "        learning_rate =[0.01,0.05],\n",
    "        lr_decay = [0.0001, 0.001], \n",
    "        momentum = [0.8, 0.95],\n",
    "        L2_reg = [2.0, 7.0], \n",
    "        dropout = [0.3, 0.6],\n",
    "        num_layers = [1,3],\n",
    "        num_nodes = [20,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_reg': 3.943359375,\n",
       " 'dropout': 0.48808593749999996,\n",
       " 'learning_rate': 0.031328125,\n",
       " 'lr_decay': 0.0005798828125,\n",
       " 'momentum': 0.80029296875,\n",
       " 'num_layers': 1.81640625,\n",
       " 'num_nodes': 23.369140625}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.6251609088129757}\n",
      "Valid metrics: {'c_index': 0.6251609088129757}\n",
      "Test metrics: {'c_index': 0.5883811172217415, 'c_index_bootstrap': {'mean': 0.5866131601633809, 'confidence_interval': (0.5843020547139969, 0.588924265612765)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.00511328125, \n",
    "              \"dropout\": 0.70808593749999996, \n",
    "              \"lr_decay\": 0.0005798828125, \n",
    "               \"momentum\": 0.10029296875, \n",
    "              \"L2_reg\": 3.943359375, \n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": False, \n",
    "              \"n_in\": 15,\n",
    "              \"hidden_layers_sizes\": [28,28,28,28,28],\n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    norm_vals = {\n",
    "            'mean' : train_data['x'].mean(axis =0),\n",
    "            'std'  : train_data['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "\n",
    "    metrics = model.train(train_data, valid_data, n_epochs = 500,\n",
    "    update_fn = utils.get_optimizer_from_str('adam'),\n",
    "    validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if hyperparams['standardize']:\n",
    "        valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, valid_data)\n",
    "    print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    test_dataset = utils.standardize_dataset(test_data, norm_vals['mean'], norm_vals['std'])\n",
    "    metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(treatment_group = False):\n",
    "    np.random.seed(123)\n",
    "    sd = deepsurv.datasets.SimulatedData(5, num_features = 15,\n",
    "        treatment_group = treatment_group)\n",
    "    train_data = sd.generate_data(2000,method = 'linear')\n",
    "    valid_data = sd.generate_data(600,method = 'linear')\n",
    "    test_data = sd.generate_data(600,method = 'linear')\n",
    "\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "train_data, valid_data, test_data = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'c_index': 0.773972482238677}\n",
      "Valid metrics: {'c_index': 0.773972482238677}\n",
      "Test metrics: {'c_index': 0.7642525898068893, 'c_index_bootstrap': {'mean': 0.763251035276291, 'confidence_interval': (0.7614059290211695, 0.7650961415314125)}}\n"
     ]
    }
   ],
   "source": [
    "hyperparams ={\"learning_rate\": 0.00511328125, \n",
    "              \"dropout\": 0.70808593749999996, \n",
    "              \"lr_decay\": 0.0005798828125, \n",
    "               \"momentum\": 0.10029296875, \n",
    "              \"L2_reg\": 3.943359375, \n",
    "              \"batch_norm\": False, \n",
    "              \"standardize\": False, \n",
    "              \"n_in\": 15,\n",
    "              \"hidden_layers_sizes\": [28,28,28,28,28],\n",
    "              \"activation\": \"selu\"}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load Dataset\n",
    "    norm_vals = {\n",
    "            'mean' : train_data['x'].mean(axis =0),\n",
    "            'std'  : train_data['x'].std(axis=0)\n",
    "        }\n",
    "\n",
    "    # Train Model\n",
    "    \n",
    "    model = DeepSurv(**hyperparams)\n",
    "\n",
    "    metrics = model.train(train_data, valid_data, n_epochs = 500,\n",
    "    update_fn = utils.get_optimizer_from_str('adam'),\n",
    "    validation_frequency = 100)\n",
    "\n",
    "    # Evaluate Model\n",
    "\n",
    "    if hyperparams['standardize']:\n",
    "        train_data = utils.standardize_dataset(train_data, norm_vals['mean'], norm_vals['std'])\n",
    "\n",
    "    metrics = evaluate_model(model, train_data)\n",
    "    print(\"Training metrics: \" + str(metrics))\n",
    "    if hyperparams['standardize']:\n",
    "        valid_data = utils.standardize_dataset(valid_data, norm_vals['mean'], norm_vals['std'])\n",
    "        metrics = evaluate_model(model, valid_data)\n",
    "    print(\"Valid metrics: \" + str(metrics))\n",
    "\n",
    "    test_dataset = utils.standardize_dataset(test_data, norm_vals['mean'], norm_vals['std'])\n",
    "    metrics = evaluate_model(model, test_dataset, bootstrap=True)\n",
    "    print(\"Test metrics: \" + str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
